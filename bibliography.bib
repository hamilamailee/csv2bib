@book{0, 
  title = "2D shading for cel animation",
}

@book{1, 
  title = "3D Shape Reconstruction from Sketches via Multi-view Convolutional Networks",
}

@book{2, 
  title = "A Challenging Benchmark of Anime Style Recognition",
}

@book{3, 
  title = "A Comprehensive Gold Standard and Benchmark for Comics Text Detection and Recognition",
}

@book{4, 
  title = "A Comprehensive Study of Deep Video Action Recognition",
}

@book{5, 
  title = "A Deep Learning Pipeline for the Synthesis of Graphic Novels",
}

@book{6, 
  title = "A Deep Learning-Based Approach for Inappropriate Content Detection and Classification of YouTube Videos",
}

@book{7, 
  title = "A Domain Gap Aware Generative Adversarial Network for Multi-domain Image Translation",
}

@book{8, 
  title = "A Drawing Support System for Sketching Aging Anime Faces",
}

@book{9, 
  title = "A Fast and Efficient Semi-guided Algorithm for Flat Coloring Line-arts",
}

@book{10, 
  title = "A Faster R-CNN Based Method for Comic Characters Face Detection",
}

@book{11, 
  title = "A Neural Representation of Sketch Drawings",
}

@book{12, 
  title = "A Note on Data Biases in Generative Models",
}

@book{13, 
  title = "A Novel Double-Tail Generative Adversarial Network for Fast Photo Animation",
}

@book{14, 
  title = "A Simple Framework for Contrastive Learning of Visual Representations",
}

@book{15, 
  title = "A Study on Generating Webtoons Using Multilingual Text-to-Image Models",
}

@book{16, 
  title = "A Study on Object Detection Method from Manga Images Using CNN",
}

@book{17, 
  title = "A Study to Achieve Manga Character Retrieval Method for Manga Images",
}

@book{18, 
  title = "A Survey of Comics Research in Computer Science",
}

@book{19, 
  title = "A Survey on Machine Reading Comprehension—Tasks, Evaluation Metrics and Benchmark Datasets",
}

@book{20, 
  title = "A Transformer-Based Model for Super-Resolution of Anime Image",
}

@book{21, 
  title = "AccessComics2: Understanding the User Experience of an Accessible Comic Book Reader for Blind People with Textual Sound Effects",
}

@book{22, 
  title = "ACFD: Asymmetric Cartoon Face Detector",
}

@book{23, 
  title = "Action2Sound: Ambient-Aware Generation of Action Sounds from Egocentric Videos",
}

@book{24, 
  title = "Adding Conditional Control to Text-to-Image Diffusion Models",
}

@book{25, 
  title = "Advancing Manga Analysis: Comprehensive Segmentation Annotations for the Manga109 Dataset",
}

@book{26, 
  title = "AgileGAN: Stylizing Portraits by Inversion-Consistent Transfer Learning",
}

@book{27, 
  title = "Alchemist: Parametric Control of Material Properties with Diffusion Models",
}

@book{28, 
  title = "Algorithms for Estimation of Comic Speakers Considering Reading Order of Frames and Texts",
}

@book{29, 
  title = "Aligning Anime Video Generation with Human Feedback",
}

@book{30, 
  title = "Alleviating Semantics Distortion in Unsupervised Low-Level Image-to-Image Translation via Structure Consistency Constraint",
}

@book{31, 
  title = "An Adaptive Control Algorithm for Stable Training of Generative Adversarial Networks",
}

@book{32, 
  title = "An Evaluation of Traditional and CNN-Based Feature Descriptors for Cartoon Pornography Detection",
}

@book{33, 
  title = "Analysis Based on Distributed Representations of Various Parts Images in Four-Scene Comics Story Dataset",
}

@book{34, 
  title = "AniDoc: Animation Creation Made Easier",
}

@book{35, 
  title = "AniFaceDrawing: Anime Portrait Exploration during Your Sketching",
}

@book{36, 
  title = "AniGAN: Style-Guided Generative Adversarial Networks for Unsupervised Anime Face Generation",
}

@book{37, 
  title = "ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video",
}

@book{38, 
  title = "Anim-Director: A Large Multimodal Model Powered Agent for Controllable Animation Video Generation",
}

@book{39, 
  title = "Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation",
}

@book{40, 
  title = "Animate-A-Story: Storytelling with Retrieval-Augmented Video Generation",
}

@book{41, 
  title = "Animate-X: Universal Character Image Animation with Enhanced Motion Representation",
}

@book{42, 
  title = "AnimateDiff-Lightning: Cross-Model Diffusion Distillation",
}

@book{43, 
  title = "Animation Anycolor: Enhancing Line Drawing Colorization with Keypoint Matching",
}

@book{44, 
  title = "Animation Line Art Colorization Based on Optical Flow Method",
}

@book{45, 
  title = "Anime Character Colorization using Few-shot Learning",
}

@book{46, 
  title = "Anime like Character Face Generation: A survey",
}

@book{47, 
  title = "Anime Sketch Coloring with Swish-gated Residual U-net and Spectrally Normalized GAN",
}

@book{48, 
  title = "Anime Sketch Colorization by Component-based Matching using Deep Appearance Features and Graph Representation",
}

@book{49, 
  title = "Anime Style Space Exploration Using Metric Learning and Generative Adversarial Networks",
}

@book{50, 
  title = "Anime Style Transfer With Spatially-Adaptive Normalization",
}

@book{51, 
  title = "Anime-to-Real Clothing: Cosplay Costume Generation via Image-to-Image Translation",
}

@book{52, 
  title = "AnimeCeleb: Large-Scale Animation CelebHeads Dataset for Head Reenactment",
}

@book{53, 
  title = "AnimeColor: Reference-based Animation Colorization with Diffusion Transformers",
}

@book{54, 
  title = "AnimeDiffusion: Anime Face Line Drawing Colorization via Diffusion Models",
}

@book{55, 
  title = "AnimeDL-2M: Million-Scale AI-Generated Anime Image Detection and Localization in Diffusion Era",
}

@book{56, 
  title = "AnimeGamer: Infinite Anime Life Simulation with Next Game State Prediction",
}

@book{57, 
  title = "AnimeGAN: a novel lightweight GAN for photo animation",
}

@book{58, 
  title = "AnimeRun: 2D Animation Visual Correspondence from Open Source 3D Movies",
}

@book{59, 
  title = "AnimeShooter: A Multi-Shot Animation Dataset for Reference-Guided Video Generation",
}

@book{60, 
  title = "AnimeSR: Learning Real-World Super-Resolution Models for Animation Videos",
}

@book{61, 
  title = "AniSora: Exploring the Frontiers of Animation Video Generation in the Sora Era",
}

@book{62, 
  title = "Anita Dataset: An Industrial Animation Dataset",
}

@book{63, 
  title = "AniWho : A Quick and Accurate Way to Classify Anime Character Faces in Images",
}

@book{64, 
  title = "APISR: Anime Production Inspired Real-World Anime Super-Resolution",
}

@book{65, 
  title = "Appearance-preserved Portrait-to-anime Translation via Proxy-guided Domain Adaptation",
}

@book{66, 
  title = "ARGAN: Fast Converging GAN for Animation Style Transfer",
}

@book{67, 
  title = "Artist-Guided Semiautomatic Animation Colorization",
}

@book{68, 
  title = "ATTENTION-AWARE ANIME LINE DRAWING COLORIZATION",
}

@book{69, 
  title = "Attention-Based Unsupervised Sketch Colorization of Anime Avatar",
}

@book{70, 
  title = "Attentioned Deep Paint",
}

@book{71, 
  title = "AttentionGAN: Unpaired Image-to-Image Translation using Attention-Guided Generative Adversarial Networks",
}

@book{72, 
  title = "Augmenting Conversations With Comic-Style Word Balloons",
}

@book{73, 
  title = "Augmenting Hand-Drawn Art with Global Illumination Effects through Surface Inflation",
}

@book{74, 
  title = "AugNet: End-to-End Unsupervised Visual Representation Learning with Image Augmentation",
}

@book{75, 
  title = "Auto-Encoding for Shared Cross Domain Feature Representation and Image-to-Image Translation",
}

@book{76, 
  title = "Auto-painter: Cartoon Image Generation from Sketch by Using Conditional Wasserstein Generative Adversarial Networks",
}

@book{77, 
  title = "Autoencoding Generative Adversarial Networks",
}

@book{78, 
  title = "Automatic Animation Inbetweening",
}

@book{79, 
  title = "Automatic Colorization of Anime Style Illustrations Using a Two-Stage Generator",
}

@book{80, 
  title = "Automatic Comic Generation with Stylistic Multi-page Layouts and Emotion-driven Text Balloon Generation",
}

@book{81, 
  title = "Automatic Comic Strip Generation Using Extracted Keyframes from Cartoon Animation",
}

@book{82, 
  title = "Automatic Dewarping of Camera-Captured Comic Document Images",
}

@book{83, 
  title = "Automatic Generation of 3D Natural Anime-like Non-Player Characters with Machine Learning",
}

@book{84, 
  title = "Automatic Illumination Effects for 2D Characters",
}

@book{85, 
  title = "Automatic Illumination of Flat-Colored Drawings by 3D Augmentation of 2D Silhouettes",
}

@book{86, 
  title = "Automatic manga colorization with color style by generative adversarial nets",
}

@book{87, 
  title = "Automatic Preview Generation of Comic Episodes for Digitized Comic Search",
}

@book{88, 
  title = "Automatic Sketch Colorization with Tandem Conditional Adversarial Networks",
}

@book{89, 
  title = "Automatic Stylistic Manga Layout",
}

@book{90, 
  title = "Automatic Temporally Coherent Video Colorization",
}

@book{91, 
  title = "BCBId: First Bangla Comic Dataset and Its Applications",
}

@book{92, 
  title = "Breaking the cycle—Colleagues are all you need",
}

@book{93, 
  title = "Bridging the Gap: Sketch-Aware Interpolation Network for High-Quality Animation Sketch Inbetweening \",
}

@book{94, 
  title = "Building a Manga Dataset ”Manga109” with Annotations for Multimedia Applications",
}

@book{95, 
  title = "C2VNet: A Deep Learning Framework Towards Comic Strip to Audio-Visual Scene Synthesis",
}

@book{96, 
  title = "CameraCtrl: Enabling Camera Control for Text-to-Video Generation",
}

@book{97, 
  title = "Caricaturation for Human Face Pictures",
}

@book{98, 
  title = "Cartoon Face Recognition: A Benchmark Dataset",
}

@book{99, 
  title = "Cartoon image colorization based on emotion recognition and superpixel color resolution",
}

@book{100, 
  title = "Cartoon Image Processing: A Survey",
}

@book{101, 
  title = "Cartoon-Flow: A Flow-Based Generative Adversarial Network for Arbitrary-Style Photo Cartoonization",
}

@book{102, 
  title = "CartoonGAN: Generative Adversarial Networks for Photo Cartoonization",
}

@book{103, 
  title = "Cartoonize Images using TinyML Strategies with Transfer Learning",
}

@book{104, 
  title = "CartoonRenderer: An Instance-based Multi-Style Cartoon Image Translator",
}

@book{105, 
  title = "CAST: CHARACTER LABELING IN ANIMATION USING SELF-SUPERVISION BY TRACKING",
}

@book{106, 
  title = "CAST: Character Labeling in Animation Using Self‐supervision by Tracking",
}

@book{107, 
  title = "cGAN-based Manga Colorization Using a Single Training Image",
}

@book{108, 
  title = "Challenges in Procedural Multimodal Machine Comprehension: A Novel Way To Benchmark",
}

@book{109, 
  title = "Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance",
}

@book{110, 
  title = "Character-Centric Story Visualization via Visual Planning and Token Alignment",
}

@book{111, 
  title = "ChartStory: Automated Partitioning, Layout, and Captioning of Charts into Comic-Style Narratives",
}

@book{112, 
  title = "Classification Representations Can be Reused for Downstream Generations",
}

@book{113, 
  title = "Closed-Form Factorization of Latent Semantics in GANs",
}

@book{114, 
  title = "CNN based Extraction of Panels/Characters from Bengali Comic Book Page Images",
}

@book{115, 
  title = "Cobra: Efficient Line Art COlorization with BRoAder References",
}

@book{116, 
  title = "CodeToon: Story Ideation, Auto Comic Generation, and Structure Mapping for Code-Driven Storytelling",
}

@book{117, 
  title = "CogCartoon: Towards Practical Story Visualization",
}

@book{118, 
  title = "Collaborative Neural Rendering using Anime Character Sheets",
}

@book{119, 
  title = "Color Attributes for Object Detection",
}

@book{120, 
  title = "Color Interpolation for Non-Euclidean Color Spaces",
}

@book{121, 
  title = "ColorFlow: Retrieval-Augmented Image Sequence Colorization",
}

@book{122, 
  title = "Coloring anime line art videos with transformation region enhancement network",
}

@book{123, 
  title = "Colorization for Anime Sketches with Cycle-Consistent Adversarial Network",
}

@book{124, 
  title = "Colorization of Line Drawings with Empty Pupils",
}

@book{125, 
  title = "ColorizeDiffusion v2: Enhancing Reference-based Sketch Colorization Through Separating Utilities",
}

@book{126, 
  title = "ColorizeDiffusion: Adjustable Sketch Colorization with Reference Image and Text",
}

@book{127, 
  title = "Combating Mode Collapse in GANs via Manifold Entropy Estimation",
}

@book{128, 
  title = "Comic Character Animation Using Bayesian Estimation",
}

@book{129, 
  title = "Comic Image Inpainting via Distance Transform",
}

@book{130, 
  title = "Comic Live Chat Communication Tool Based on Concept of Downgrading",
}

@book{131, 
  title = "Comic MTL: Optimized Multi-Task Learning for Comic Book Image Analysis",
}

@book{132, 
  title = "Comic Story Analysis Based on Genre Classification",
}

@book{133, 
  title = "Comic-Guided Speech Synthesis",
}

@book{134, 
  title = "ComiCap: A VLMs pipeline for dense captioning of Comic Panels",
}

@book{135, 
  title = "ComicBERT: A Transformer Model and Pre-training Strategy for Contextual Understanding in Comics",
}

@book{136, 
  title = "ComicGAN: Text-to-Comic Generative Adversarial Network",
}

@book{137, 
  title = "ComicLib: A New Large-Scale Comic Dataset for Sketch Understanding",
}

@book{138, 
  title = "Comicolorization: Semi-Automatic Manga Colorization",
}

@book{139, 
  title = "ComicQA: Contextual Navigation Aid by Hyper-Comic Representation",
}

@book{140, 
  title = "Comics as a Pedagogical Tool for Teaching",
}

@book{141, 
  title = "Comics Datasets Framework: Mix of Comics datasets for detection benchmarking",
}

@book{142, 
  title = "Comics for Everyone: Generating Accessible Text Descriptions for Comic Strips",
}

@book{143, 
  title = "CoMix: A Comprehensive Benchmark for Multi-Task Comic Understanding",
}

@book{144, 
  title = "Comixify: Transform video into a comics",
}

@book{145, 
  title = "Competition on Multimodal Emotion Recognition on Comics Scenes",
}

@book{146, 
  title = "Computational Approaches to Comics Analysis",
}

@book{147, 
  title = "Conditional GAN for Small Datasets",
}

@book{148, 
  title = "Content-Aware Video2Comics With Manga-Style Layout",
}

@book{149, 
  title = "Context-Informed Machine Translation of Manga using Multimodal Large Language Models",
}

@book{150, 
  title = "Continual few-shot patch-based learning for anime-style colorization",
}

@book{151, 
  title = "Controlling StyleGANs Using Rough Scribbles via One-shot Learning",
}

@book{152, 
  title = "COO: Comic Onomatopoeia Dataset for Recognizing Arbitrary or Truncated Texts",
}

@book{153, 
  title = "COO/ Comic Onomatopoeia Dataset for Recognizing Arbitrary or Truncated Texts",
}

@book{154, 
  title = "CoPE: Conditional image generation using Polynomial Expansions",
}

@book{155, 
  title = "CPD: Faster RCNN-based DragonBall Comic Panel Detection",
}

@book{156, 
  title = "CPTNet: Cascade Pose Transform Network for Single Image Talking Head Animation",
}

@book{157, 
  title = "Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions",
}

@book{158, 
  title = "Creative Flow+ Dataset",
}

@book{159, 
  title = "Cross-Domain and Disentangled Face Manipulation with 3D Guidance",
}

@book{160, 
  title = "Cross-Domain Style Mixing for Face Cartoonization",
}

@book{161, 
  title = "Cross-Domain Weakly-Supervised Object Detection through Progressive Domain Adaptation",
}

@book{162, 
  title = "Cross-modal and Semantics-Augmented Asymmetric CycleGAN for Data-Imbalanced Anime Style Face Translation",
}

@book{163, 
  title = "CustomCrafter: Customized Video Generation with Preserving Motion and Concept Composition Abilities",
}

@book{164, 
  title = "DA-GAN: Instance-level Image Translation by Deep Attention Generative Adversarial Networks",
}

@book{165, 
  title = "DAF:RE: A CHALLENGING, CROWD-SOURCED, LARGE-SCALE, LONG-TAILED DATASET FOR ANIME CHARACTER RECOGNITION",
}

@book{166, 
  title = "DanbooRegion: An Illustration Region Dataset",
}

@book{167, 
  title = "DASS-Detector: Domain-Adaptive Self-Supervised Pre-Training for Face \& Body Detection in Drawings",
}

@book{168, 
  title = "Data InStance Prior (DISP) in Generative Adversarial Networks",
}

@book{169, 
  title = "DATA INSTANCE PRIOR FOR TRANSFER LEARNING IN GANS",
}

@book{170, 
  title = "Decomposing Images into Layers with Advanced Color Blending",
}

@book{171, 
  title = "Deep Animation Video Interpolation in the Wild",
}

@book{172, 
  title = "Deep Edge-Aware Interactive Colorization against Color-Bleeding Effects",
}

@book{173, 
  title = "Deep Extraction of Manga Structural Lines",
}

@book{174, 
  title = "Deep Geometrized Cartoon Line Inbetweening",
}

@book{175, 
  title = "Deep Learning-Based Classification of the Polar Emotions of “Moe”-Style Cartoon Pictures",
}

@book{176, 
  title = "Deep Line Art Video Colorization with a Few References",
}

@book{177, 
  title = "Deep Manga Colorization with Color Style Extraction by Conditional Adversarially Learned Inference",
}

@book{178, 
  title = "Deep Normal Estimation for Automatic Shading of Hand-Drawn Characters",
}

@book{179, 
  title = "Deep Sketch-guided Cartoon Video Inbetweening",
}

@book{180, 
  title = "Deep Unfolding with Normalizing Flow Priors for Inverse Problems",
}

@book{181, 
  title = "Deep-Eyes: Fully Automatic Anime Character Colorization with Painting of Details on Empty Pupils",
}

@book{182, 
  title = "Dense Multitask Learning to Reconfigure Comics",
}

@book{183, 
  title = "Depixelizing Pixel Art",
}

@book{184, 
  title = "Designing a Question-Answering System for Comic Contents",
}

@book{185, 
  title = "Developing Comic-based Learning Toolkits for Teaching Computing to Elementary School Learners",
}

@book{186, 
  title = "Diff-Foley: Synchronized Video-to-Audio Synthesis with Latent Diffusion Models",
}

@book{187, 
  title = "DiffSensei: Bridging Multi-Modal LLMs and Diffusion Models for Customized Manga Generation",
}

@book{188, 
  title = "Diffusart: Enhancing Line Art Colorization with Conditional Diffusion Models",
}

@book{189, 
  title = "Diffusion in Style",
}

@book{190, 
  title = "Diffutoon: High-Resolution Editable Toon Shading via Diffusion Models",
}

@book{191, 
  title = "DiLight: Digital light table – Inbetweening for 2D animations using guidelines",
}

@book{192, 
  title = "Discovering Density-Preserving Latent Space Walks in GANs for Semantic Image Transformations",
}

@book{193, 
  title = "Discovering Interpretable Latent Space Directions of GANs Beyond Binary Attributes",
}

@book{194, 
  title = "DisenStudio: Customized Multi-Subject Text-to-Video Generation with Disentangled Spatial Control",
}

@book{195, 
  title = "Disentangled and controllable sketch creation based ondisentangling the structure and color enhancement",
}

@book{196, 
  title = "Disentangling Style and Content in Anime Illustrations",
}

@book{197, 
  title = "DisUnknown: Distilling Unknown Factors for Disentanglement Learning",
}

@book{198, 
  title = "Do Generative Models Know Disentanglement? Contrastive Learning is All You Need",
}

@book{199, 
  title = "Do You Like Sclera? Sclera-region Detection and Colorization for Anime Character Line Drawings",
}

@book{200, 
  title = "Document Classification and Page Stream Segmentation for Digital Mailroom Applications",
}

@book{201, 
  title = "DoveNet: Deep Image Harmonization via Domain Verification",
}

@book{202, 
  title = "Dr.Bokeh: DiffeRentiable Occlusion-aware Bokeh Rendering",
}

@book{203, 
  title = "DrawingSpinUp: 3D Animation from Single Character Drawings",
}

@book{204, 
  title = "DreamArtist: Towards Controllable One-Shot Text-to-Image Generation via Positive-Negative Prompt-Tuning",
}

@book{205, 
  title = "DreamDance: Animating Character Art via Inpainting Stable Gaussian Worlds",
}

@book{206, 
  title = "DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation",
}

@book{207, 
  title = "DreamTuner: Single Image is Enough for Subject-Driven Generation",
}

@book{208, 
  title = "DreamVideo: High-Fidelity Image-to-Video Generation with Image Retention and Text Guidance",
}

@book{209, 
  title = "DreamWaltz: Make a Scene with Complex 3D Animatable Avatars",
}

@book{210, 
  title = "Dual Color Space Guided Sketch Colorization",
}

@book{211, 
  title = "Dual Loss for Manga Character Recognition with Imbalanced Training Data",
}

@book{212, 
  title = "Dynamic Manga: Animating Still Manga via Camera Movement",
}

@book{213, 
  title = "DyStyle: Dynamic Neural Network for Multi-Attribute-Conditioned Style Editing",
}

@book{214, 
  title = "Efficient Continual Adaptation for Generative Adversarial Networks",
}

@book{215, 
  title = "EigenGAN: Layer-Wise Eigen-Learning for GANs",
}

@book{216, 
  title = "Eliminating Gradient Conflict in Reference-based Line-Art Colorization",
}

@book{217, 
  title = "EmoDubber: Towards High Quality and Emotion Controllable Movie Dubbing",
}

@book{218, 
  title = "Encoding in Style: A StyleGAN Encoder for Image-to-Image Translation",
}

@book{219, 
  title = "End-to-End Line Drawing Vectorization",
}

@book{220, 
  title = "Enhanced Deep Animation Video Interpolation",
}

@book{221, 
  title = "Enhancement of Anime Imaging Enlargement using Modified Super-Resolution CNN",
}

@book{222, 
  title = "Enhancing the Accessibility for All of Digital Comic Books",
}

@book{223, 
  title = "Erasing Appearance Preservation in Optimization-based Smoothing",
}

@book{224, 
  title = "Estimating Image Depth in the Comics Domain",
}

@book{225, 
  title = "Exemplar-Based Sketch Colorization with Cross-Domain Dense Semantic Correspondence",
}

@book{226, 
  title = "Exploiting Aliasing for Manga Restoration",
}

@book{227, 
  title = "Exploring inbetween charts with trajectory-guided sliders for cutout animation",
}

@book{228, 
  title = "Exploring Phrase Grounding without Training: Contextualisation and Extension to Text-Based Image Retrieval",
}

@book{229, 
  title = "Exploring Sketch-based Character Design Guided by Automatic Colorization",
}

@book{230, 
  title = "Extraction of Frame Sequences in the Manga Context",
}

@book{231, 
  title = "Facial Landmark Detection for Manga Images",
}

@book{232, 
  title = "FairyGen: Storied Cartoon Video from a Single Child-Drawn Character",
}

@book{233, 
  title = "Fast Leak-Resistant Segmentation for Anime Line Art",
}

@book{234, 
  title = "Feature Quantization Improves GAN Training",
}

@book{235, 
  title = "FEW-SHOT ADAPTATION OF GENERATIVE ADVERSARIAL NETWORKS",
}

@book{236, 
  title = "Few-shot Knowledge Transfer for Fine-grained Cartoon Face Generation",
}

@book{237, 
  title = "Few-shot Semantic Image Synthesis Using StyleGAN Prior",
}

@book{238, 
  title = "Fine-Grained Control of Artistic Styles in Image Generation",
}

@book{239, 
  title = "FINE-TUNING STYLEGAN2 FOR CARTOON FACE GENERATION",
}

@book{240, 
  title = "FlatMagic: Improving Flat Colorization through AI-driven Design for Digital Comic Professionals",
}

@book{241, 
  title = "Floating No More: Object-Ground Reconstruction from a Single Image",
}

@book{242, 
  title = "Foley Music: Learning to Generate Music from Videos",
}

@book{243, 
  title = "FoleyGen: Visually-Guided Audio Generation",
}

@book{244, 
  title = "Framer: Interactive Frame Interpolation",
}

@book{245, 
  title = "Freeze the Discriminator: a Simple Baseline for Fine-Tuning GANs",
}

@book{246, 
  title = "FRESCO: Spatial-Temporal Correspondence for Zero-Shot Video Translation",
}

@book{247, 
  title = "From Speaker to Dubber: Movie Dubbing with Prosody and Duration Consistency Learning",
}

@book{248, 
  title = "Full-body High-resolution Anime Generation with Progressive Structure-conditional Generative Adversarial Networks",
}

@book{249, 
  title = "Fully Automatic Colorization for Anime Character Considering Accurate Eye Colors",
}

@book{250, 
  title = "GAN Memory with No Forgetting",
}

@book{251, 
  title = "GAN-based Multi-Style Photo Cartoonization",
}

@book{252, 
  title = "GANILLA: Generative adversarial networks for image to illustration translation",
}

@book{253, 
  title = "GANs N’ Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!)",
}

@book{254, 
  title = "GCN-Based Multi-Modal Multi-Label Attribute Classification in Anime Illustration Using Domain-Specific Semantic Features",
}

@book{255, 
  title = "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
}

@book{256, 
  title = "Generate Novel Image Styles using Weighted Hybrid Generative Adversarial Nets",
}

@book{257, 
  title = "Generating "Ideal" Anime Opening Frames Using Neural Networks",
}

@book{258, 
  title = "Generating Anime from Real Human Image with Adversarial Training",
}

@book{259, 
  title = "Generating Coherent Comic with Rich Story Using ChatGPT and Stable Diffusion",
}

@book{260, 
  title = "Generating Digital Painting Lighting Effects via RGB-space Geometry",
}

@book{261, 
  title = "Generating Full-Body Standing Figures of Anime Characters and Its Style Transfer by GAN",
}

@book{262, 
  title = "Generating Manga from Illustrations via Mimicking Manga Creation Workflow",
}

@book{263, 
  title = "Generating Manga from Illustrations via Mimicking Manga Workflow",
}

@book{264, 
  title = "Generating Visual Stories with Grounded and Coreferent Characters",
}

@book{265, 
  title = "Generative Adversarial Networks for photo to Hayao Miyazaki style cartoons",
}

@book{266, 
  title = "Generative AI for Cel-Animation: A Survey",
}

@book{267, 
  title = "Generative Omnimatte: Learning to Decompose Video into Layers",
}

@book{268, 
  title = "Generative Probabilistic Image Colorization",
}

@book{269, 
  title = "Globally Optimal Toon Tracking",
}

@book{270, 
  title = "Good Artists Copy, Great Artists Steal: Model Extraction Attacks Against Image Translation Generative Adversarial Networks",
}

@book{271, 
  title = "GPT-4",
}

@book{272, 
  title = "Graph Jigsaw Learning for Cartoon Face Recognition",
}

@book{273, 
  title = "Graph Matching based Anime Colorization with Multiple References",
}

@book{274, 
  title = "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection",
}

@book{275, 
  title = "GroundVLP: Harnessing Zero-shot Visual Grounding from Vision-Language Pre-training and Open-Vocabulary Object Detection",
}

@book{276, 
  title = "Guiding Users to Where to Give Color Hints for Efficient Interactive Sketch Colorization via Unsupervised Region Prioritization",
}

@book{277, 
  title = "Hair Shading Style Transfer for Manga with cGAN",
}

@book{278, 
  title = "Hierarchical Feature Warping and Blending for Talking Head Animation",
}

@book{279, 
  title = "Hierarchical Multi-Label Attribute Classification With Graph Convolutional Networks on Anime Illustration",
}

@book{280, 
  title = "High-Resolution Image Harmonization via Collaborative Dual Transformations",
}

@book{281, 
  title = "High-Resolution Image Synthesis with Latent Diffusion Models",
}

@book{282, 
  title = "HistoGAN: Controlling Colors of GAN-Generated and Real Images via Color Histograms",
}

@book{283, 
  title = "Histogram of Exclamation Marks and Its Application for Comics Analysis",
}

@book{284, 
  title = "HoLLMwood: Unleashing the Creativity of Large Language Models in Screenwriting via Role Playing",
}

@book{285, 
  title = "How to train your conditional GAN: An approach using geometrically structured latent manifolds",
}

@book{286, 
  title = "HRInversion: High-Resolution GAN Inversion for Cross-Domain Image Synthesis",
}

@book{287, 
  title = "Human-Art: A Versatile Human-Centric Dataset Bridging Natural and Artificial Scenes",
}

@book{288, 
  title = "Hyprogan: Breaking the Dimensional wall From Human to Anime",
}

@book{289, 
  title = "I Hear Your True Colors: Image Guided Audio Generation",
}

@book{290, 
  title = "Identity-Aware Semi-Supervised Learning for Comic Character Re-Identification",
}

@book{291, 
  title = "Illustration2Vec: A Semantic Vector Representation of Illustrations",
}

@book{292, 
  title = "Image Colorization: A Survey and Dataset",
}

@book{293, 
  title = "Image Generation From Small Datasets via Batch Statistics Adaptation",
}

@book{294, 
  title = "Image Referenced Sketch Colorization Based on Animation Creation Workflow",
}

@book{295, 
  title = "Image-to-Image Translation with Conditional Adversarial Networks",
}

@book{296, 
  title = "Improving Generation and Evaluation of Visual Stories via Semantic Consistency",
}

@book{297, 
  title = "Improving Reference-Based Image Colorization For Line Arts Via Feature Aggregation And Contrastive Learning",
}

@book{298, 
  title = "Improving Shape Deformation in Unsupervised Image-to-Image Translation",
}

@book{299, 
  title = "Improving the Perceptual Quality of 2D Animation Interpolation",
}

@book{300, 
  title = "Improving The Quality Of Illustrations: Transforming Amateur Illustrations To A Professional Standard",
}

@book{301, 
  title = "Ink-and-Ray: Bas-Relief Meshes for Adding Global Illumination Effects to Hand-Drawn Characters",
}

@book{302, 
  title = "Inkn'hue: Enhancing Manga Colorization from Multiple Priors with Alignment Multi-Encoder VAE",
}

@book{303, 
  title = "Instance-guided Cartoon Editing with a Large-scale Dataset",
}

@book{304, 
  title = "Integrating Visuospatial, Linguistic and Commonsense Structure intoStory Visualization",
}

@book{305, 
  title = "Intelligent Grimm -- Open-ended Visual Storytelling via Latent Diffusion Models",
}

@book{306, 
  title = "Interactive Anime Sketch Colorization with Style Consistency via a Deep Residual Neural Network",
}

@book{307, 
  title = "Interactive Cartoonization with Controllable Perceptual Factors",
}

@book{308, 
  title = "Interactive Data Comics",
}

@book{309, 
  title = "Interactive Manga Colorization with Fast Flat Coloring",
}

@book{310, 
  title = "InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks",
}

@book{311, 
  title = "Interpolation based Anime Face Style Transfer",
}

@book{312, 
  title = "Intrinsic Image Harmonization",
}

@book{313, 
  title = "Investigating Neural Networks and Transformer Models for Enhanced Comic Decoding",
}

@book{314, 
  title = "Joint Geometric-Semantic Driven Character Line Drawing Generation",
}

@book{315, 
  title = "Joint Stroke Tracing and Correspondence for 2D Animation",
}

@book{316, 
  title = "JoJoGAN: One Shot Face Stylization",
}

@book{317, 
  title = "KidsGUARD: Fine Grained Approach for Child Unsafe Video Representation and Detection",
}

@book{318, 
  title = "L2M-GAN: Learning to Manipulate Latent Space Semantics for Facial Attribute Editing",
}

@book{319, 
  title = "Landmark Assisted CycleGAN for Cartoon Face Generation",
}

@book{320, 
  title = "Language-Guided Face Animation by Recurrent StyleGAN-based Generator",
}

@book{321, 
  title = "LANIT: Language-Driven Image-to-Image Translation for Unlabeled Data",
}

@book{322, 
  title = "Large Language Models as Manga Translators: A Case Study",
}

@book{323, 
  title = "Late-resizing: A Simple but Effective Sketch Extraction Strategy for Improving Generalization of Line-art Colorization",
}

@book{324, 
  title = "LayerAnimate: Layer-specific Control for Animation",
}

@book{325, 
  title = "LayoutGAN: Generating Graphic Layouts with Wireframe Discriminators",
}

@book{326, 
  title = "Learning Consensus Representation for Weak Style Classification",
}

@book{327, 
  title = "Learning from the Past: Meta-Continual Learning withKnowledge Embedding for Jointly Sketch, Cartoon, andCaricature Face Recognition",
}

@book{328, 
  title = "Learning Inclusion Matching for Animation Paint Bucket Coloriation",
}

@book{329, 
  title = "Learning Inclusion Matching for Animation Paint Bucket Colorization",
}

@book{330, 
  title = "Learning Inclusion Matching for Animation Paint Bucket Colorization",
}

@book{331, 
  title = "Learning to Cartoonize Using White-box Cartoon Representations",
}

@book{332, 
  title = "Learning to Dub Movies via Hierarchical Prosody Models",
}

@book{333, 
  title = "Learning to Incorporate Texture Saliency Adaptive Attention to Image Cartoonization",
}

@book{334, 
  title = "Learning to Shadow Hand-drawn Sketches",
}

@book{335, 
  title = "Learning to Simplify: Fully Convolutional Networks for Rough Sketch Cleanup",
}

@book{336, 
  title = "Line Art Colorization Based on Explicit Region Segmentation",
}

@book{337, 
  title = "Line Art Colorization with Concatenated Spatial Attention",
}

@book{338, 
  title = "Line Art Correlation Matching Feature Transfer Network for Automatic Animation Colorization",
}

@book{339, 
  title = "Line-Based Drawing Style Description for Manga Classification",
}

@book{340, 
  title = "Line-Wise Text Identification in Comic Books: A Support Vector Machine-Based Approach",
}

@book{341, 
  title = "LinkTo-Anime: A 2D Animation Optical Flow Dataset from 3D Model Rendering",
}

@book{342, 
  title = "LongAnimation: Long Animation Generation with Dynamic Global-Local Memory",
}

@book{343, 
  title = "LVCD: Reference-based Lineart Video Colorization with Diffusion Models",
}

@book{344, 
  title = "LVCD: Reference-based Lineart Video Colorization with Diffusion Models",
}

@book{345, 
  title = "M2C: Towards Automatic Multimodal Manga Complement",
}

@book{346, 
  title = "MagicAnime: A Hierarchically Annotated, Multimodal and Multitasking Dataset with Benchmarks for Cartoon Animation Generation",
}

@book{347, 
  title = "Make-A-Story: Visual Memory Conditioned Consistent Story Generation",
}

@book{348, 
  title = "Make-A-Storyboard: A General Framework for Storyboard with Disentangled and Merged Control",
}

@book{349, 
  title = "MakeItTalk: Speaker-Aware Talking-Head Animation",
}

@book{350, 
  title = "Making Robots Draw A Vivid Portrait In Two Minutes",
}

@book{351, 
  title = "Manga Colorization",
}

@book{352, 
  title = "Manga Content Analysis Using Physiological Signals",
}

@book{353, 
  title = "Manga Filling Style Conversion with Screentone Variational Autoencoder",
}

@book{354, 
  title = "Manga Generation via Layout-controllable Diffusion",
}

@book{355, 
  title = "Manga Rescreening with Interpretable Screentone Representation",
}

@book{356, 
  title = "Manga Text Detection with Manga-Specific Data Augmentation and Its Applications on Emotion Analysis",
}

@book{357, 
  title = "Manga Vectorization and Manipulation with Procedural Simple Screentone",
}

@book{358, 
  title = "Manga-MMTL: Multimodal Multitask Transfer Learning for Manga Character Analysis",
}

@book{359, 
  title = "Manga109Dialog A Large-scale Dialogue Dataset for Comics Speaker Detection",
}

@book{360, 
  title = "Manga109Dialog: A Large-scale Dialogue Dataset for Comics Speaker Detection",
}

@book{361, 
  title = "MangaGAN: Unpaired Photo-to-Manga Translation Based on The Methodology of Manga Drawing",
}

@book{362, 
  title = "MANGAN: ASSISTING COLORIZATION OF MANGA CHARACTERS CONCEPT ART USING CONDITIONAL GAN",
}

@book{363, 
  title = "MangaNinja: Line Art Colorization with Precise Reference Following",
}

@book{364, 
  title = "MangaUB: A Manga Understanding Benchmark for Large Multimodal Models",
}

@book{365, 
  title = "MaRU: A Manga Retrieval and Understanding System Connecting Vision and Language",
}

@book{366, 
  title = "MARVEL: Raster Gray-level Manga Vectorization via Primitive-wise Deep Reinforcement Learning",
}

@book{367, 
  title = "Mastering Sketching: Adversarial Augmentation for Structured Prediction",
}

@book{368, 
  title = "MeLFusion: Synthesizing Music from Image and Language Cues using Diffusion Models",
}

@book{369, 
  title = "Method for Automatic E-Comic Scene Frame Extraction for Reading Comic on Mobile Devices",
}

@book{370, 
  title = "Method for Real Time Text Extraction of Digital Manga Comic",
}

@book{371, 
  title = "MikuDance: Animating Character Art with Mixed Motion Dynamics",
}

@book{372, 
  title = "MimicMotion: High-Quality Human Motion Video Generation with Confidence-aware Pose Guidance",
}

@book{373, 
  title = "Mind the Gap: Domain Gap Control for Single Shot Domain Adaptation for Generative Adversarial Networks",
}

@book{374, 
  title = "Mind the Time: Temporally-Controlled Multi-Event Video Generation",
}

@book{375, 
  title = "MineGAN: effective knowledge transfer from GANs to target domains with few images",
}

@book{376, 
  title = "MineGAN++: Mining Generative Models for Efficient Knowledge Transfer to Limited Data Domains",
}

@book{377, 
  title = "Modeling Artistic Workflows for Image Generation and Editing",
}

@book{378, 
  title = "MontageGAN: Generation and Assembly of Multiple Components by GANs",
}

@book{379, 
  title = "Motion-Conditioned Image Animation for Video Editing",
}

@book{380, 
  title = "Movie2Comics: Towards a Lively Video Content Presentation",
}

@book{381, 
  title = "MulT: An End-to-End Multitask Learning Transformer",
}

@book{382, 
  title = "Multi-CartoonGAN for Conditional Artistic Face Translation",
}

@book{383, 
  title = "Multi-Density Sketch-to-Image Translation Network",
}

@book{384, 
  title = "Multi-modal Segment Assemblage Network for Ad Video Editing with Importance-Coherence Reward",
}

@book{385, 
  title = "Multi-Teacher Knowledge Distillation For Text Image Machine Translation",
}

@book{386, 
  title = "Multimodal Persona Based Generation of Comic Dialogs",
}

@book{387, 
  title = "Multimodal Transformer for Comics Text-Cloze",
}

@book{388, 
  title = "Neural Optimal Transport",
}

@book{389, 
  title = "Object Detection for Comics using Manga109 Annotations",
}

@book{390, 
  title = "ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion",
}

@book{391, 
  title = "Occlusion-Aware Manga Character Re-Identification with Self-Paced Contrastive Learning",
}

@book{392, 
  title = "One missing peace in Vision & Language: A survey on Comics Understanding",
}

@book{393, 
  title = "One missing piece in Vision and Language: A Survey on Comics Understanding",
}

@book{394, 
  title = "One-shot Line Extraction from Color Illustrations",
}

@book{395, 
  title = "Open-Vocabulary DETR with Conditional Matching",
}

@book{396, 
  title = "Optical Flow Based Line Drawing Frame Interpolation Using Distance Transform to Support Inbetweenings",
}

@book{397, 
  title = "Outline Colorization through Tandem Adversarial Networks",
}

@book{398, 
  title = "Overcoming Long-term Catastrophic Forgetting through Adversarial Neural Pruning and Synaptic Consolidation",
}

@book{399, 
  title = "Page Stream Segmentation with Convolutional Neural Nets Combining Textual and Visual Features",
}

@book{400, 
  title = "Paint Bucket Colorization Using Anime Character Color Design Sheets",
}

@book{401, 
  title = "PAINTING STYLE-AWARE MANGA COLORIZATION BASED ON GENERATIVE ADVERSARIAL NETWORKS",
}

@book{402, 
  title = "PaintsTorch: a User-Guided Anime Line Art Colorization Tool with Double Generator Conditional Adversarial Network",
}

@book{403, 
  title = "Panel and Speech Balloon Extraction from Comic Books",
}

@book{404, 
  title = "Panel Tracking for the Extraction and the Classification of Speech Balloons",
}

@book{405, 
  title = "Panel-Page-Aware Comic Genre Understanding",
}

@book{406, 
  title = "PAniC-3D: Stylized Single-view 3D Reconstruction from Portraits of Anime Characters",
}

@book{407, 
  title = "Parsing-Conditioned Anime Translation: A New Dataset and Method",
}

@book{408, 
  title = "Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer",
}

@book{409, 
  title = "PCT-Net: Full Resolution Image Harmonization Using Pixel-Wise Color Transformations",
}

@book{410, 
  title = "Perceptual-aware Sketch Simplification Based on Integrated VGG Layers",
}

@book{411, 
  title = "Personalised CLIP or: How to Find Your Vacation Videos",
}

@book{412, 
  title = "Personalized Comic Story Generation",
}

@book{413, 
  title = "PHOG Analysis of Self-Similarity in Aesthetic Images",
}

@book{414, 
  title = "Photorealistic Video Generation with Diffusion Models",
}

@book{415, 
  title = "PhysAnimator: Physics-Guided Generative Cartoon Animation",
}

@book{416, 
  title = "PI-REC: Progressive Image Reconstruction Network With Edge and Color Domain",
}

@book{417, 
  title = "PMSGAN: Parallel Multistage GANs for Face Image Translation",
}

@book{418, 
  title = "Pose Estimation of Anime/Manga Characters: A Case for Synthetic Data",
}

@book{419, 
  title = "Potrace : A Polygon-Based Tracing Algorithm",
}

@book{420, 
  title = "Progressive Deep Feature Learning for Manga Character Recognition via Unlabeled Training Data",
}

@book{421, 
  title = "Progressive Full Data Convolutional Neural Networks for Line Extraction from Anime-Style Illustrations",
}

@book{422, 
  title = "PromptFix: You Prompt and We Fix the Photo",
}

@book{423, 
  title = "Pseudo-Supervised Learning for Semantic Multi-Style Transfer",
}

@book{424, 
  title = "Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond",
}

@book{425, 
  title = "RAG: Facial Attribute Editing by Learning Residual Attributes",
}

@book{426, 
  title = "Raster Manga Vectorization via Primitive-wise Deep Reinforcement Learning",
}

@book{427, 
  title = "Re:Draw -- Context Aware Translation as a Controllable Method for Artistic Production",
}

@book{428, 
  title = "Real-ESRGAN: Training Real-World Blind Super-Resolution with Pure Synthetic Data",
}

@book{429, 
  title = "Real-Time Data-Driven Interactive Rough Sketch Inking",
}

@book{430, 
  title = "Recognizing Text Elements for SVG Comic Compression and Its Novel Applications",
}

@book{431, 
  title = "Reference Based Sketch Extraction via Attention Mechanism",
}

@book{432, 
  title = "Reference-base Image Composition with Sketch via Structure-aware Diffusion Model",
}

@book{433, 
  title = "Reference-based Manga Colorization by Graph Correspondence Using Quadratic Programming",
}

@book{434, 
  title = "Reference-Based Sketch Image Colorization using Augmented-Self Reference and Dense Semantic Correspondence",
}

@book{435, 
  title = "Reference-guided structure-aware deep sketch colorization for cartoons",
}

@book{436, 
  title = "Reframe Anything: LLM Agent for Open World Video Reframing",
}

@book{437, 
  title = "Relation Analysis between Speech Balloon Shapes and Their Serif Descriptions in Comic",
}

@book{438, 
  title = "Research and Development of the Generation in Japanese Manga Based on Frontal Face Image",
}

@book{439, 
  title = "Robust Manga Page Colorization via Coloring Latent Space",
}

@book{440, 
  title = "RPGAN: GANs Interpretability via Random Routing",
}

@book{441, 
  title = "Sakuga-42M Dataset: Scaling Up Cartoon Research",
}

@book{442, 
  title = "Scalable Comic-like Video Summaries and Layout Disturbance",
}

@book{443, 
  title = "Scaling Concept With Text-Guided Diffusion Models",
}

@book{444, 
  title = "Scaling In-the-Wild Training for Diffusion-based Illumination Harmonization and Editing by Imposing Consistent Light Transport",
}

@book{445, 
  title = "Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation",
}

@book{446, 
  title = "Seamless Manga Inpainting with Semantics Awareness",
}

@book{447, 
  title = "Searching Digital Political Cartoons",
}

@book{448, 
  title = "SEED-Story: Multimodal Long Story Generation with Large Language Model",
}

@book{449, 
  title = "Seg2pix: Few Shot Training Line Art Colorization with Segmented Image Data",
}

@book{450, 
  title = "Self-supervised Enhancement of Latent Discovery in GANs",
}

@book{451, 
  title = "Semantic Example Guided Image-to-Image Translation",
}

@book{452, 
  title = "Semantic Parsing of Interpage Relations",
}

@book{453, 
  title = "Semi-Auto Sketch Colorization Based on Conditional Generative Adversarial Networks",
}

@book{454, 
  title = "Semi-Automatic Colorization Pipeline for Anime Characters and its Evaluation in Production",
}

@book{455, 
  title = "Semi-automatic Manga Colorization Using Conditional Adversarial Networks",
}

@book{456, 
  title = "Semi-supervised reference-based sketch extraction using a contrastive learning framework",
}

@book{457, 
  title = "Shading-Guided Manga Screening from Reference",
}

@book{458, 
  title = "Similar Manga Retrieval Using Visual Vocabulary Based on Regions of Interest",
}

@book{459, 
  title = "Similarity Learning Based on Pool-Based Active Learning for Manga Character Retrieval",
}

@book{460, 
  title = "Skeleton-Driven Inbetweening of Bitmap Character Drawings",
}

@book{461, 
  title = "Sketch-A-Shape: Zero-Shot Sketch-to-3D Shape Generation",
}

@book{462, 
  title = "Sketch-based Anime Hairstyle Editing with Generative Inpainting",
}

@book{463, 
  title = "Sketch-Based Manga Retrieval Using Deep Features",
}

@book{464, 
  title = "Sketch-based Manga Retrieval using Manga109 Dataset",
}

@book{465, 
  title = "Sketch-Guided Scene Image Generation",
}

@book{466, 
  title = "Sketch2Anim: Towards Transferring Sketch Storyboards into 3D Animation",
}

@book{467, 
  title = "SKETCH2MANGA: SHADED MANGA SCREENING FROM SKETCH WITH DIFFUSION MODELS",
}

@book{468, 
  title = "Sketch2Manga: Sketch-based Manga Retrieval",
}

@book{469, 
  title = "SketchBetween: Video-to-Video Synthesis for Sprite Animation via Sketches",
}

@book{470, 
  title = "SketchColour: Channel Concat Guided DiT-based Sketch-to-Colour Pipeline for 2D Animation",
}

@book{471, 
  title = "SketchMan: Learning to Create Professional Sketches",
}

@book{472, 
  title = "SmartPaint: a co-creative drawing system based on generative adversarial networks",
}

@book{473, 
  title = "SmartShadow: Artistic Shadow Drawing Tool for Line Drawings",
}

@book{474, 
  title = "SPatchGAN: A Statistical Feature Based Discriminator for Unsupervised Image-to-Image Translation",
}

@book{475, 
  title = "Spatially Augmented Speech Bubble to Character Association via Comic Multi-task Learning",
}

@book{476, 
  title = "Spatially Controllable Image Synthesis with Internal Representation Collaging",
}

@book{477, 
  title = "Speech Balloon and Speaker Association for Comics and Manga Understanding",
}

@book{478, 
  title = "Sprite-from-Sprite: Cartoon Animation Decomposition with Self-supervised Sprite Estimation",
}

@book{479, 
  title = "SSH: A Self-Supervised Framework for Image Harmonization",
}

@book{480, 
  title = "SSIMBaD: Sigma Scaling with SSIM-Guided Balanced Diffusion for AnimeFace Colorization",
}

@book{481, 
  title = "SSN: Soft Shadow Network for Image Compositing",
}

@book{482, 
  title = "StarGAN Based Facial Expression Transfer for Anime Characters",
}

@book{483, 
  title = "StdGEN: Semantic-Decomposed 3D Character Generation from Single Images",
}

@book{484, 
  title = "StencilTorch: An Iterative and User-Guided Framework for Anime Lineart Colorization",
}

@book{485, 
  title = "Stereoscopizing Cel Animations",
}

@book{486, 
  title = "Story Pattern Analysis Based on Scene Order Information in Four-Scene Comics",
}

@book{487, 
  title = "StoryDALL-E: Adapting Pretrained Text-to-Image Transformers for Story Continuation",
}

@book{488, 
  title = "StoryGAN: A Sequential Conditional GAN for Story Visualization",
}

@book{489, 
  title = "StoryImager: A Unified and Efficient Framework for Coherent Story Visualization and Completion",
}

@book{490, 
  title = "StoryWeaver: A Unified World Model for Knowledge-Enhanced Story Character Customization",
}

@book{491, 
  title = "Style Transfer for Anime Sketches with Enhanced Residual U-net and Auxiliary Classifier GAN",
}

@book{492, 
  title = "StyleDubber: Towards Multi-Scale Style Learning for Movie Dubbing",
}

@book{493, 
  title = "StyleGAN-NADA: CLIP-Guided Domain Adaptation of Image Generators",
}

@book{494, 
  title = "StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces",
}

@book{495, 
  title = "Styleverse: Towards Identity Stylization across Heterogeneous Domains",
}

@book{496, 
  title = "Stylized-Colorization for Line Arts",
}

@book{497, 
  title = "StyO: Stylize Your Face in Only One-Shot",
}

@book{498, 
  title = "Surrogate Gradient Field for Latent Space Manipulation",
}

@book{499, 
  title = "Synthesis of Screentone Patterns of Manga Characters",
}

@book{500, 
  title = "Synthesizing Coherent Story with Auto-Regressive Latent Diffusion Models",
}

@book{501, 
  title = "Tag2Pix: Line Art Colorization Using Text Tag With SECat and Changing Loss",
}

@book{502, 
  title = "Tails Tell Tales: Chapter-Wide Manga Transcriptions with Character Names",
}

@book{503, 
  title = "Taming Visually Guided Sound Generation",
}

@book{504, 
  title = "Temporal Noise Control for Sketchy Animation",
}

@book{505, 
  title = "Text Detection in Manga by Combining Connected-Component-Based and Region-Based Classifications",
}

@book{506, 
  title = "Text Detection in Manga by Deep Region Proposal, Classification, and Regression",
}

@book{507, 
  title = "Text-Aware Balloon Extraction from Manga",
}

@book{508, 
  title = "Textoon: Generating Vivid 2D Cartoon Characters from Text Descriptions",
}

@book{509, 
  title = "TexToons: Practical Texture Mapping for Hand-drawn Cartoon Animations",
}

@book{510, 
  title = "The Amazing Mysteries of the Gutter: Drawing Inferences Between Panels in Comic Book Narratives",
}

@book{511, 
  title = "The Animation Transformer: Visual Correspondence via Segment Matching",
}

@book{512, 
  title = "The Future of Graphic Novel Translation: Fully Automated Systems",
}

@book{513, 
  title = "The Manga Whisperer: Automatically Generating Transcriptions for Comics",
}

@book{514, 
  title = "The Visual Language Research Corpus (VLRC) Project",
}

@book{515, 
  title = "Thin-Plate Spline-based Interpolation for Animation Line Inbetweening",
}

@book{516, 
  title = "Thinking Outside the BBox: Unconstrained Generative Object Compositing",
}

@book{517, 
  title = "TokenFlow: Consistent Diffusion Features for Consistent Video Editing",
}

@book{518, 
  title = "Toon3D: Seeing Cartoons from a New Perspective",
}

@book{519, 
  title = "ToonCrafter: Generative Cartoon Interpolation",
}

@book{520, 
  title = "Toonsynth: example-based synthesis of hand-colored cartoon animations",
}

@book{521, 
  title = "Toward Accessible Comics for Blind and Low Vision Readers",
}

@book{522, 
  title = "Toward Cross-Domain Object Detection in Artwork Images Using Improved YoloV5 and XGBoosting",
}

@book{523, 
  title = "Towards Content-Aware Pixel-Wise Comic Panel Segmentation",
}

@book{524, 
  title = "Towards Diverse and Faithful One-shot Adaption of Generative Adversarial Networks",
}

@book{525, 
  title = "Towards Diverse Anime Face Generation: Active Label Completion and Style Feature Network",
}

@book{526, 
  title = "Towards Fully Automated Manga Translation",
}

@book{527, 
  title = "Towards Layer-wise Image Vectorization",
}

@book{528, 
  title = "Towards Solving Multimodal Comprehension",
}

@book{529, 
  title = "Towards the Automatic Anime Characters Creation with Generative Adversarial Networks",
}

@book{530, 
  title = "Transfer Learning for Pose Estimation of Illustrated Characters",
}

@book{531, 
  title = "Transfer photo to anime with dual discriminators GAN",
}

@book{532, 
  title = "Translation of Illustration Artist Style Using Sailormoonredraw Data",
}

@book{533, 
  title = "TransPixar: Advancing Text-to-Video Generation with Transparency",
}

@book{534, 
  title = "Turn Real People into Anime Cartoonization",
}

@book{535, 
  title = "Twin-GAN – Unpaired Cross-Domain Image Translation with Weight-Sharing GANs",
}

@book{536, 
  title = "Two-stage Sketch Colorization",
}

@book{537, 
  title = "Two-Stage Sketch Colorization With Color Parsing",
}

@book{538, 
  title = "Two-Step Training: Adjustable Sketch Colourization via Reference Image and Text Tag",
}

@book{539, 
  title = "U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation",
}

@book{540, 
  title = "Unaligned Image-to-Image Translation by Learning to Reweight",
}

@book{541, 
  title = "Unbiased Mean Teacher for Cross-domain Object Detection",
}

@book{542, 
  title = "Unconstrained Text Detection in Manga: a New Dataset and Baseline",
}

@book{543, 
  title = "Universal Face Restoration With Memorized Modulation",
}

@book{544, 
  title = "Unlocking Comics: The AI4VA Dataset for Visual Understanding",
}

@book{545, 
  title = "Unpaired Cartoon Image Synthesis via Gated Cycle Mapping",
}

@book{546, 
  title = "Unpaired Image-to-Image Translation using Adversarial Consistency Loss",
}

@book{547, 
  title = "Unpaired Image-to-Image Translation using Negative Learning for Noisy Patches",
}

@book{548, 
  title = "Unpaired Sketch-to-Line Translation via Synthesis of Sketches",
}

@book{549, 
  title = "Unsupersived Image Texture Transfer Based On Generative Adversarial Network",
}

@book{550, 
  title = "Unsupervised Coherent Video Cartoonization with Perceptual Motion Consistency",
}

@book{551, 
  title = "Unsupervised Colorization of Black-and-White Cartoons",
}

@book{552, 
  title = "Unsupervised Discovery of Disentangled Interpretable Directions for Layer-Wise GAN",
}

@book{553, 
  title = "Unsupervised Discovery of Disentangled Manifolds in GANs",
}

@book{554, 
  title = "Unsupervised Discovery of Interpretable Directions in the GAN Latent Space",
}

@book{555, 
  title = "Unsupervised Image-to-Image Translation via Pre-trained StyleGAN2 Network",
}

@book{556, 
  title = "Unsupervised Learning of Compositional Energy Concepts",
}

@book{557, 
  title = "Unsupervised Manga Character Re-identification via Face-body and Spatial-temporal Associated Clustering",
}

@book{558, 
  title = "User Guided Digital Artwork Colorization",
}

@book{559, 
  title = "User-Guided Deep Anime Line Art Colorization with Conditional Adversarial Networks",
}

@book{560, 
  title = "User-Guided Line Art Flat Filling with Split Filling Mechanism",
}

@book{561, 
  title = "Using Comics to Introduce and Reinforce Programming Concepts in CS1",
}

@book{562, 
  title = "UVCGAN: UNET VISION TRANSFORMER CYCLE-CONSISTENT GAN FOR UNPAIRED IMAGE-TO-IMAGE TRANSLATION",
}

@book{563, 
  title = "V2C: Visual Voice Cloning",
}

@book{564, 
  title = "V2Meow: Meowing to the Visual Beat via Video-to-Music Generation",
}

@book{565, 
  title = "Video2Music: Suitable Music Generation from Videos using an Affective Multimodal Transformer model",
}

@book{566, 
  title = "VideoComposer: Compositional Video Synthesis with Motion Controllability",
}

@book{567, 
  title = "VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning",
}

@book{568, 
  title = "VideoStudio: Generating Consistent-Content and Multi-Scene Videos",
}

@book{569, 
  title = "VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling",
}

@book{570, 
  title = "Visual adaptation in translated comics",
}

@book{571, 
  title = "Vlogger: Make Your Dream A Vlog",
}

@book{572, 
  title = "VLPose: Bridging the Domain Gap in Pose Estimation with Language-Vision Tuning",
}

@book{573, 
  title = "VToonify: Controllable High-Resolution Portrait Video Style Transfer",
}

@book{574, 
  title = "What Do We Expect from Comic Panel Extraction?",
}

@book{575, 
  title = "Zero-Shot Character Identification and Speaker Prediction in Comics via Iterative Multimodal Fusion",
}

@book{576, 
  title = "Zero-Shot Object Detection with Textual Descriptions",
}

