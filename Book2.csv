Title,
"2D shading for cel animation",
"A Comprehensive Gold Standard and Benchmark for Comics Text Detection and Recognition",
"A Comprehensive Study of Deep Video Action Recognition",
"A Deep Learning Pipeline for the Synthesis of Graphic Novels",
"A Deep Learning-Based Approach for Inappropriate Content Detection and Classification of YouTube Videos",
"A Drawing Support System for Sketching Aging Anime Faces",
"A Faster R-CNN Based Method for Comic Characters Face Detection",
"A Neural Representation of Sketch Drawings",
"A Note on Data Biases in Generative Models",
"A Novel Double-Tail Generative Adversarial Network for Fast Photo Animation",
"A Simple Framework for Contrastive Learning of Visual Representations",
"A Survey on Machine Reading Comprehension—Tasks, Evaluation Metrics and Benchmark Datasets",
"AccessComics2: Understanding the User Experience of an Accessible Comic Book Reader for Blind People with Textual Sound Effects",
"Adding Conditional Control to Text-to-Image Diffusion Models",
"AgileGAN: Stylizing Portraits by Inversion-Consistent Transfer Learning",
"Algorithms for Estimation of Comic Speakers Considering Reading Order of Frames and Texts",
"Analysis Based on Distributed Representations of Various Parts Images in Four-Scene Comics Story Dataset",
"ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video",
"Animate-X: Universal Character Image Animation with Enhanced Motion Representation",
"AnimateDiff-Lightning: Cross-Model Diffusion Distillation",
"Animation Anycolor: Enhancing Line Drawing Colorization with Keypoint Matching",
"Animation Line Art Colorization Based on Optical Flow Method",
"Anime Character Colorization using Few-shot Learning",
"Anime like Character Face Generation: A survey",
"Anime Sketch Coloring with Swish-gated Residual U-net and Spectrally Normalized GAN",
"Anime Style Space Exploration Using Metric Learning and Generative Adversarial Networks",
"AnimeCeleb: Large-Scale Animation CelebHeads Dataset for Head Reenactment",
"AnimeColor: Reference-based Animation Colorization with Diffusion Transformers",
"AnimeDL-2M: Million-Scale AI-Generated Anime Image Detection and Localization in Diffusion Era",
"AnimeGamer: Infinite Anime Life Simulation with Next Game State Prediction",
"AnimeGAN: a novel lightweight GAN for photo animation",
"AnimeSR: Learning Real-World Super-Resolution Models for Animation Videos",
"Anita Dataset: An Industrial Animation Dataset ",
"AniWho : A Quick and Accurate Way to Classify Anime Character Faces in Images",
"Artist-Guided Semiautomatic Animation Colorization",
"ATTENTION-AWARE ANIME LINE DRAWING COLORIZATION",
"Attention-Based Unsupervised Sketch Colorization of Anime Avatar",
"Attentioned Deep Paint",
"AttentionGAN: Unpaired Image-to-Image Translation using Attention-Guided Generative Adversarial Networks",
"Augmenting Conversations With Comic-Style Word Balloons",
"Autoencoding Generative Adversarial Networks",
"Automatic Animation Inbetweening",
"Automatic Illumination Effects for 2D Characters",
"Automatic Sketch Colorization with Tandem Conditional Adversarial Networks",
"Automatic Temporally Coherent Video Colorization",
"Breaking the cycle—Colleagues are all you need",
"Bridging the Gap: Sketch-Aware Interpolation Network for High-Quality Animation Sketch Inbetweening \",
"Building a Manga Dataset ”Manga109” with Annotations for Multimedia Applications",
"CameraCtrl: Enabling Camera Control for Text-to-Video Generation",
"Caricaturation for Human Face Pictures",
"Cartoon Face Recognition: A Benchmark Dataset",
"Cartoon image colorization based on emotion recognition and superpixel color resolution",
"Cartoon Image Processing: A Survey",
"Cartoon-Flow: A Flow-Based Generative Adversarial Network for Arbitrary-Style Photo Cartoonization",
"Cartoonize Images using TinyML Strategies with Transfer Learning",
"CartoonRenderer: An Instance-based Multi-Style Cartoon Image Translator",
"CAST: CHARACTER LABELING IN ANIMATION USING SELF-SUPERVISION BY TRACKING",
"CAST: Character Labeling in Animation Using Self‐supervision by Tracking",
"cGAN-based Manga Colorization Using a Single Training Image",
"ChartStory: Automated Partitioning, Layout, and Captioning of Charts into Comic-Style Narratives",
"Classification Representations Can be Reused for Downstream Generations",
"Cobra: Efficient Line Art COlorization with BRoAder References",
"CogCartoon: Towards Practical Story Visualization",
"Color Attributes for Object Detection",
"Color Interpolation for Non-Euclidean Color Spaces",
"ColorFlow: Retrieval-Augmented Image Sequence Colorization",
"Coloring anime line art videos with transformation region enhancement network",
"Colorization for Anime Sketches with Cycle-Consistent Adversarial Network",
"Colorization of Line Drawings with Empty Pupils",
"ColorizeDiffusion v2: Enhancing Reference-based Sketch Colorization Through Separating Utilities",
"ColorizeDiffusion: Adjustable Sketch Colorization with Reference Image and Text",
"Combating Mode Collapse in GANs via Manifold Entropy Estimation",
"Comic Character Animation Using Bayesian Estimation",
"Comic Image Inpainting via Distance Transform",
"Comic Live Chat Communication Tool Based on Concept of Downgrading",
"Comic Story Analysis Based on Genre Classification",
"ComicBERT: A Transformer Model and Pre-training Strategy for Contextual Understanding in Comics",
"ComicLib: A New Large-Scale Comic Dataset for Sketch Understanding",
"Comicolorization: Semi-Automatic Manga Colorization",
"ComicQA: Contextual Navigation Aid by Hyper-Comic Representation",
"Comics as a Pedagogical Tool for Teaching",
"Comics Datasets Framework: Mix of Comics datasets for detection benchmarking",
"Competition on Multimodal Emotion Recognition on Comics Scenes",
"Computational Approaches to Comics Analysis",
"Conditional GAN for Small Datasets",
"Continual few-shot patch-based learning for anime-style colorization ",
"Controlling StyleGANs Using Rough Scribbles via One-shot Learning",
"COO/ Comic Onomatopoeia Dataset for Recognizing Arbitrary or Truncated Texts",
"Creative Flow+ Dataset",
"Cross-Domain and Disentangled Face Manipulation with 3D Guidance",
"Cross-Domain Style Mixing for Face Cartoonization",
"CustomCrafter: Customized Video Generation with Preserving Motion and Concept Composition Abilities",
"DA-GAN: Instance-level Image Translation by Deep Attention Generative Adversarial Networks",
"DAF:RE: A CHALLENGING, CROWD-SOURCED, LARGE-SCALE, LONG-TAILED DATASET FOR ANIME CHARACTER RECOGNITION",
"DASS-Detector: Domain-Adaptive Self-Supervised Pre-Training for Face \& Body Detection in Drawings",
"DATA INSTANCE PRIOR FOR TRANSFER LEARNING IN GANS",
"Decomposing Images into Layers with Advanced Color Blending",
"Deep Animation Video Interpolation in the Wild",
"Deep Edge-Aware Interactive Colorization against Color-Bleeding Effects",
"Deep Learning-Based Classification of the Polar Emotions of “Moe”-Style Cartoon Pictures",
"Dense Multitask Learning to Reconfigure Comics",
"DiffSensei: Bridging Multi-Modal LLMs and Diffusion Models for Customized Manga Generation",
"Diffusion in Style",
"Diffutoon: High-Resolution Editable Toon Shading via Diffusion Models",
"DiLight: Digital light table – Inbetweening for 2D animations using guidelines",
"DisenStudio: Customized Multi-Subject Text-to-Video Generation with Disentangled Spatial Control",
"Disentangled and controllable sketch creation based ondisentangling the structure and color enhancement",
"DisUnknown: Distilling Unknown Factors for Disentanglement Learning",
"Do You Like Sclera? Sclera-region Detection and Colorization for Anime Character Line Drawings",
"Document Classification and Page Stream Segmentation for Digital Mailroom Applications",
"DoveNet: Deep Image Harmonization via Domain Verification",
"Dr.Bokeh: DiffeRentiable Occlusion-aware Bokeh Rendering",
"DrawingSpinUp: 3D Animation from Single Character Drawings",
"DreamArtist: Towards Controllable One-Shot Text-to-Image Generation via Positive-Negative Prompt-Tuning",
"DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation",
"Dual Color Space Guided Sketch Colorization",
"Dual Loss for Manga Character Recognition with Imbalanced Training Data",
"DyStyle: Dynamic Neural Network for Multi-Attribute-Conditioned Style Editing",
"Efficient Continual Adaptation for Generative Adversarial Networks",
"EmoDubber: Towards High Quality and Emotion Controllable Movie Dubbing",
"Encoding in Style: A StyleGAN Encoder for Image-to-Image Translation",
"End-to-End Line Drawing Vectorization",
"Erasing Appearance Preservation in Optimization-based Smoothing",
"Exemplar-Based Sketch Colorization with Cross-Domain Dense Semantic Correspondence",
"Exploring Sketch-based Character Design Guided by Automatic Colorization",
"Extraction of Frame Sequences in the Manga Context",
"Fast Leak-Resistant Segmentation for Anime Line Art",
"Feature Quantization Improves GAN Training",
"FEW-SHOT ADAPTATION OF GENERATIVE ADVERSARIAL NETWORKS",
"Few-shot Semantic Image Synthesis Using StyleGAN Prior",
"Fine-Grained Control of Artistic Styles in Image Generation",
"Floating No More: Object-Ground Reconstruction from a Single Image",
"FoleyGen: Visually-Guided Audio Generation",
"Framer: Interactive Frame Interpolation",
"From Speaker to Dubber: Movie Dubbing with Prosody and Duration Consistency Learning",
"Full-body High-resolution Anime Generation with Progressive Structure-conditional Generative Adversarial Networks",
"Fully Automatic Colorization for Anime Character Considering Accurate Eye Colors",
"GAN Memory with No Forgetting",
"GAN-based Multi-Style Photo Cartoonization",
"GANILLA: Generative adversarial networks for image to illustration translation",
"GANs N’ Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!)",
"GANs N‚Äô Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!)",
"Generating Coherent Comic with Rich Story Using ChatGPT and Stable Diffusion",
"Generating Full-Body Standing Figures of Anime Characters and Its Style Transfer by GAN",
"Generating Manga from Illustrations via Mimicking Manga Creation Workflow",
"Generating Visual Stories with Grounded and Coreferent Characters",
"Generative Probabilistic Image Colorization",
"Good Artists Copy, Great Artists Steal: Model Extraction Attacks Against Image Translation Generative Adversarial Networks",
"GPT-4",
"Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection",
"GroundVLP: Harnessing Zero-shot Visual Grounding from Vision-Language Pre-training and Open-Vocabulary Object Detection",
"Guiding Users to Where to Give Color Hints for Efficient Interactive Sketch Colorization via Unsupervised Region Prioritization",
"Hair Shading Style Transfer for Manga with cGAN",
"High-Resolution Image Synthesis with Latent Diffusion Models",
"HistoGAN: Controlling Colors of GAN-Generated and Real Images via Color Histograms",
"How to train your conditional GAN: An approach using geometrically structured latent manifolds",
"HRInversion: High-Resolution GAN Inversion for Cross-Domain Image Synthesis",
"Human-Art: A Versatile Human-Centric Dataset Bridging Natural and Artificial Scenes",
"Hyprogan: Breaking the Dimensional wall From Human to Anime",
"Identity-Aware Semi-Supervised Learning for Comic Character Re-Identification",
"Image Colorization: A Survey and Dataset",
"Image-to-Image Translation with Conditional Adversarial Networks",
"Improving Shape Deformation in Unsupervised Image-to-Image Translation",
"Improving the Perceptual Quality of 2D Animation Interpolation",
"Ink-and-Ray: Bas-Relief Meshes for Adding Global Illumination Effects to Hand-Drawn Characters",
"Integrating Visuospatial, Linguistic and Commonsense Structure intoStory Visualization",
"Intelligent Grimm -- Open-ended Visual Storytelling via Latent Diffusion Models",
"Interactive Cartoonization with Controllable Perceptual Factors",
"Interactive Data Comics",
"Interactive Manga Colorization with Fast Flat Coloring",
"InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks",
"Intrinsic Image Harmonization",
"Joint Geometric-Semantic Driven Character Line Drawing Generation",
"Joint Stroke Tracing and Correspondence for 2D Animation",
"KidsGUARD: Fine Grained Approach for Child Unsafe Video Representation and Detection",
"L2M-GAN: Learning to Manipulate Latent Space Semantics for Facial Attribute Editing",
"Landmark Assisted CycleGAN for Cartoon Face Generation",
"Language-Guided Face Animation by Recurrent StyleGAN-based Generator",
"Large Language Models as Manga Translators: A Case Study",
"LayoutGAN: Generating Graphic Layouts with Wireframe Discriminators",
"Learning Consensus Representation for Weak Style Classification",
"Learning from the Past: Meta-Continual Learning withKnowledge Embedding for Jointly Sketch, Cartoon, andCaricature Face Recognition",
"Learning Inclusion Matching for Animation Paint Bucket Coloriation",
"Learning Inclusion Matching for Animation Paint Bucket Colorization",
"Learning Inclusion Matching for Animation Paint Bucket Colorization ",
"Learning to Cartoonize Using White-box Cartoon Representations",
"Learning to Dub Movies via Hierarchical Prosody Models",
"Learning to Simplify: Fully Convolutional Networks for Rough Sketch Cleanup",
"Line Art Correlation Matching Feature Transfer Network for Automatic Animation Colorization",
"Line-Wise Text Identification in Comic Books: A Support Vector Machine-Based Approach",
"LinkTo-Anime: A 2D Animation Optical Flow Dataset from 3D Model Rendering",
"LVCD: Reference-based Lineart Video Colorization with Diffusion Models",
"LVCD: Reference-based Lineart Video Colorization with Diffusion Models ",
"Make-A-Storyboard: A General Framework for Storyboard with Disentangled and Merged Control",
"MakeItTalk: Speaker-Aware Talking-Head Animation",
"Making Robots Draw A Vivid Portrait In Two Minutes",
"Manga Colorization",
"Manga Rescreening with Interpretable Screentone Representation",
"Manga Vectorization and Manipulation with Procedural Simple Screentone",
"Manga-MMTL: Multimodal Multitask Transfer Learning for Manga Character Analysis",
"Manga109Dialog A Large-scale Dialogue Dataset for Comics Speaker Detection",
"Manga109Dialog: A Large-scale Dialogue Dataset for Comics Speaker Detection",
"MangaGAN: Unpaired Photo-to-Manga Translation Based on The Methodology of Manga Drawing",
"MANGAN: ASSISTING COLORIZATION OF MANGA CHARACTERS CONCEPT ART USING CONDITIONAL GAN",
"MangaNinja: Line Art Colorization with Precise Reference Following",
"MangaUB: A Manga Understanding Benchmark for Large Multimodal Models",
"Mastering Sketching: Adversarial Augmentation for Structured Prediction",
"Method for Automatic E-Comic Scene Frame Extraction for Reading Comic on Mobile Devices",
"Method for Real Time Text Extraction of Digital Manga Comic",
"MineGAN++: Mining Generative Models for Efficient Knowledge Transfer to Limited Data Domains",
"Modeling Artistic Workflows for Image Generation and Editing",
"Motion-Conditioned Image Animation for Video Editing",
"MulT: An End-to-End Multitask Learning Transformer",
"Multi-CartoonGAN for Conditional Artistic Face Translation",
"Multi-modal Segment Assemblage Network for Ad Video Editing with Importance-Coherence Reward",
"Multi-Teacher Knowledge Distillation For Text Image Machine Translation",
"Multimodal Transformer for Comics Text-Cloze",
"Neural Optimal Transport",
"Object Detection for Comics using Manga109 Annotations",
"ObjectDrop: Bootstrapping Counterfactuals for Photorealistic Object Removal and Insertion",
"Occlusion-Aware Manga Character Re-Identification with Self-Paced Contrastive Learning",
"One missing peace in Vision & Language: A survey on Comics Understanding",
"Optical Flow Based Line Drawing Frame Interpolation Using Distance Transform to Support Inbetweenings",
"Overcoming Long-term Catastrophic Forgetting through Adversarial Neural Pruning and Synaptic Consolidation",
"Page Stream Segmentation with Convolutional Neural Nets Combining Textual and Visual Features",
"PAINTING STYLE-AWARE MANGA COLORIZATION BASED ON GENERATIVE ADVERSARIAL NETWORKS",
"PaintsTorch: a User-Guided Anime Line Art Colorization Tool with Double Generator Conditional Adversarial Network",
"PAniC-3D: Stylized Single-view 3D Reconstruction from Portraits of Anime Characters",
"Parsing-Conditioned Anime Translation: A New Dataset and Method",
"Personalised CLIP or: How to Find Your Vacation Videos",
"Personalized Comic Story Generation",
"PHOG Analysis of Self-Similarity in Aesthetic Images",
"Photorealistic Video Generation with Diffusion Models",
"PhysAnimator: Physics-Guided Generative Cartoon Animation",
"PI-REC: Progressive Image Reconstruction Network With Edge and Color Domain",
"Progressive Deep Feature Learning for Manga Character Recognition via Unlabeled Training Data",
"Pseudo-Supervised Learning for Semantic Multi-Style Transfer",
"RAG: Facial Attribute Editing by Learning Residual Attributes",
"Raster Manga Vectorization via Primitive-wise Deep Reinforcement Learning",
"Re:Draw -- Context Aware Translation as a Controllable Method for Artistic Production",
"Real-Time Data-Driven Interactive Rough Sketch Inking",
"Reference-base Image Composition with Sketch via Structure-aware Diffusion Model",
"Relation Analysis between Speech Balloon Shapes and Their Serif Descriptions in Comic",
"RPGAN: GANs Interpretability via Random Routing",
"Sakuga-42M Dataset: Scaling Up Cartoon Research ",
"Scalable Comic-like Video Summaries and Layout Disturbance",
"Scaling Concept With Text-Guided Diffusion Models",
"Seamless Manga Inpainting with Semantics Awareness",
"Seg2pix: Few Shot Training Line Art Colorization with Segmented Image Data",
"Self-supervised Enhancement of Latent Discovery in GANs",
"Semantic Example Guided Image-to-Image Translation",
"Semi-Automatic Colorization Pipeline for Anime Characters and its Evaluation in Production",
"Semi-automatic Manga Colorization Using Conditional Adversarial Networks",
"Similar Manga Retrieval Using Visual Vocabulary Based on Regions of Interest",
"Skeleton-Driven Inbetweening of Bitmap Character Drawings",
"Sketch-A-Shape: Zero-Shot Sketch-to-3D Shape Generation",
"Sketch-based Anime Hairstyle Editing with Generative Inpainting",
"Sketch-Based Manga Retrieval Using Deep Features",
"Sketch-Guided Scene Image Generation",
"Sketch2Anim: Towards Transferring Sketch Storyboards into 3D Animation",
"SketchColour: Channel Concat Guided DiT-based Sketch-to-Colour Pipeline for 2D Animation",
"SmartShadow: Artistic Shadow Drawing Tool for Line Drawings",
"Spatially Controllable Image Synthesis with Internal Representation Collaging",
"Sprite-from-Sprite: Cartoon Animation Decomposition with Self-supervised Sprite Estimation",
"SSH: A Self-Supervised Framework for Image Harmonization",
"StarGAN Based Facial Expression Transfer for Anime Characters",
"Story Pattern Analysis Based on Scene Order Information in Four-Scene Comics",
"StyleDubber: Towards Multi-Scale Style Learning for Movie Dubbing",
"StyleGAN-NADA: CLIP-Guided Domain Adaptation of Image Generators",
"StyleGANEX: StyleGAN-Based Manipulation Beyond Cropped Aligned Faces",
"Stylized-Colorization for Line Arts",
"Surrogate Gradient Field for Latent Space Manipulation",
"Synthesis of Screentone Patterns of Manga Characters",
"Taming Visually Guided Sound Generation",
"Text Detection in Manga by Deep Region Proposal, Classification, and Regression",
"TexToons: Practical Texture Mapping for Hand-drawn Cartoon Animations",
"The Amazing Mysteries of the Gutter: Drawing Inferences Between Panels in Comic Book Narratives",
"The Future of Graphic Novel Translation: Fully Automated Systems",
"The Visual Language Research Corpus (VLRC) Project",
"Thin-Plate Spline-based Interpolation for Animation Line Inbetweening",
"Toon3D: Seeing Cartoons from a New Perspective",
"Toonsynth: example-based synthesis of hand-colored cartoon animations",
"Toward Cross-Domain Object Detection in Artwork Images Using Improved YoloV5 and XGBoosting",
"Towards Content-Aware Pixel-Wise Comic Panel Segmentation",
"Towards Diverse Anime Face Generation: Active Label Completion and Style Feature Network",
"Towards Fully Automated Manga Translation",
"Towards Layer-wise Image Vectorization",
"Towards Solving Multimodal Comprehension",
"Transfer Learning for Pose Estimation of Illustrated Characters",
"Translation of Illustration Artist Style Using Sailormoonredraw Data",
"TransPixar: Advancing Text-to-Video Generation with Transparency",
"Turn Real People into Anime Cartoonization",
"Twin-GAN – Unpaired Cross-Domain Image Translation with Weight-Sharing GANs",
"Twin-GAN ‚Äì Unpaired Cross-Domain Image Translation with Weight-Sharing GANs",
"Two-stage Sketch Colorization",
"Two-Stage Sketch Colorization With Color Parsing",
"Two-Step Training: Adjustable Sketch Colourization via Reference Image and Text Tag",
"U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation",
"Unaligned Image-to-Image Translation by Learning to Reweight",
"Unconstrained Text Detection in Manga: a New Dataset and Baseline",
"Universal Face Restoration With Memorized Modulation",
"Unpaired Image-to-Image Translation using Adversarial Consistency Loss",
"Unpaired Image-to-Image Translation using Negative Learning for Noisy Patches",
"Unpaired Sketch-to-Line Translation via Synthesis of Sketches",
"Unsupervised Discovery of Disentangled Manifolds in GANs",
"Unsupervised Discovery of Interpretable Directions in the GAN Latent Space",
"Unsupervised Image-to-Image Translation via Pre-trained StyleGAN2 Network",
"Unsupervised Learning of Compositional Energy Concepts",
"Unsupervised Manga Character Re-identification via Face-body and Spatial-temporal Associated Clustering",
"User Guided Digital Artwork Colorization",
"User-Guided Deep Anime Line Art Colorization with Conditional Adversarial Networks",
"User-Guided Line Art Flat Filling with Split Filling Mechanism",
"Using Comics to Introduce and Reinforce Programming Concepts in CS1",
"V2C: Visual Voice Cloning",
"Video2Music: Suitable Music Generation from Videos using an Affective Multimodal Transformer model",
"VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning",
"VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling",
"Visual adaptation in translated comics",
"VToonify: Controllable High-Resolution Portrait Video Style Transfer",
"What Do We Expect from Comic Panel Extraction?",
"Zero-Shot Object Detection with Textual Descriptions",