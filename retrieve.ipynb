{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4acc655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import string\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42268eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./Notion.csv\"\n",
    "\n",
    "df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d75a4d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Key Findings</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Status</th>\n",
       "      <th>URL</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Citation</th>\n",
       "      <th>Source</th>\n",
       "      <th>Title_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anime Sketch Coloring with Swish-gated Residua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>anime sketch coloring with swish gated residua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anita Dataset: An Industrial Animation Dataset</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-Animation-Research</td>\n",
       "      <td>anita dataset  an industrial animation dataset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attentioned Deep Paint</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>attentioned deep paint</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Automatic Animation Inbetweening</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>automatic animation inbetweening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automatic Illumination Effects for 2D Characters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>automatic illumination effects for 2d characters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breaking the cycle—Colleagues are all you need</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>breaking the cycle—colleagues are all you need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bridging the Gap: Sketch-Aware Interpolation N...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-Animation-Research</td>\n",
       "      <td>bridging the gap  sketch aware interpolation n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Building a Manga Dataset ”Manga109” with Annot...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>building a manga dataset ”manga109” with annot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CAST: CHARACTER LABELING IN ANIMATION USING SE...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>cast  character labeling in animation using se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Competition on Multimodal Emotion Recognition ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>awesome-comics-understanding</td>\n",
       "      <td>competition on multimodal emotion recognition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Continual few-shot patch-based learning for an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-Animation-Research</td>\n",
       "      <td>continual few shot patch based learning for an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Controlling StyleGANs Using Rough Scribbles vi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>controlling stylegans using rough scribbles vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DAF:RE: A CHALLENGING, CROWD-SOURCED, LARGE-SC...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>daf re  a challenging  crowd sourced  large sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DASS-Detector: Domain-Adaptive Self-Supervised...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>awesome-comics-understanding</td>\n",
       "      <td>dass detector  domain adaptive self supervised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Deep Learning-Based Classification of the Pola...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>deep learning based classification of the pola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Disentangled and controllable sketch creation ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>disentangled and controllable sketch creation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DreamWaltz: Make a Scene with Complex 3D Anima...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>dreamwaltz  make a scene with complex 3d anima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DyStyle: Dynamic Neural Network for Multi-Attr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>dystyle  dynamic neural network for multi attr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GANs N’ Roses: Stable, Controllable, Diverse I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>gans n’ roses  stable  controllable  diverse i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Generating Full-Body Standing Figures of Anime...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>generating full body standing figures of anime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-AI4Animation</td>\n",
       "      <td>gpt 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Integrating Visuospatial, Linguistic and Commo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>awesome-comics-understanding</td>\n",
       "      <td>integrating visuospatial  linguistic and commo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Intelligent Grimm -- Open-ended Visual Storyte...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-AI4Animation</td>\n",
       "      <td>intelligent grimm    open ended visual storyte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InternVL: Scaling up Vision Foundation Models ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-AI4Animation</td>\n",
       "      <td>internvl  scaling up vision foundation models ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Learning from the Past: Meta-Continual Learnin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>learning from the past  meta continual learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Learning Inclusion Matching for Animation Pain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>learning inclusion matching for animation pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Learning Inclusion Matching for Animation Pain...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-Animation-Research</td>\n",
       "      <td>learning inclusion matching for animation pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Learning to Simplify: Fully Convolutional Netw...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>learning to simplify  fully convolutional netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LVCD: Reference-based Lineart Video Colorizati...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-Animation-Research</td>\n",
       "      <td>lvcd  reference based lineart video colorizati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Manga109Dialog A Large-scale Dialogue Dataset ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>awesome-comics-understanding</td>\n",
       "      <td>manga109dialog a large scale dialogue dataset ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Mastering Sketching: Adversarial Augmentation ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>mastering sketching  adversarial augmentation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MulT: An End-to-End Multitask Learning Transfo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>awesome-comics-understanding</td>\n",
       "      <td>mult  an end to end multitask learning transfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Multi-CartoonGAN for Conditional Artistic Face...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>multi cartoongan for conditional artistic face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Occlusion-Aware Manga Character Re-Identificat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>awesome-comics-understanding</td>\n",
       "      <td>occlusion aware manga character re identificat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>One missing peace in Vision &amp; Language: A surv...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>one missing peace in vision   language  a surv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Personalized Comic Story Generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>awesome-comics-understanding</td>\n",
       "      <td>personalized comic story generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Raster Manga Vectorization via Primitive-wise ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>raster manga vectorization via primitive wise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Re:Draw -- Context Aware Translation as a Cont...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-AI4Animation, Awesome-Animation-Resear...</td>\n",
       "      <td>re draw    context aware translation as a cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Reference-base Image Composition with Sketch v...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>reference base image composition with sketch v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Sakuga-42M Dataset: Scaling Up Cartoon Research</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-Animation-Research</td>\n",
       "      <td>sakuga 42m dataset  scaling up cartoon research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SketchColour: Channel Concat Guided DiT-based ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-Animation-Research</td>\n",
       "      <td>sketchcolour  channel concat guided dit based ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Sprite-from-Sprite: Cartoon Animation Decompos...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-AI4Animation, Awesome-Animation-Resear...</td>\n",
       "      <td>sprite from sprite  cartoon animation decompos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>StyleGAN-NADA: CLIP-Guided Domain Adaptation o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>stylegan nada  clip guided domain adaptation o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>The Visual Language Research Corpus (VLRC) Pro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>awesome-comics-understanding</td>\n",
       "      <td>the visual language research corpus  vlrc  pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Toon3D: Seeing Cartoons from a New Perspective</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-Animation-Research</td>\n",
       "      <td>toon3d  seeing cartoons from a new perspective</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Toonsynth: example-based synthesis of hand-col...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-AI4Animation, Awesome-Animation-Research</td>\n",
       "      <td>toonsynth  example based synthesis of hand col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>TransPixar: Advancing Text-to-Video Generation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-AI4Animation</td>\n",
       "      <td>transpixar  advancing text to video generation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Twin-GAN – Unpaired Cross-Domain Image Transla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>twin gan – unpaired cross domain image transla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Two-Step Training: Adjustable Sketch Colouriza...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AwesomeAnimeResearch</td>\n",
       "      <td>two step training  adjustable sketch colouriza...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Visual adaptation in translated comics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>awesome-comics-understanding</td>\n",
       "      <td>visual adaptation in translated comics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>VToonify: Controllable High-Resolution Portrai...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To Assess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Awesome-AI4Animation</td>\n",
       "      <td>vtoonify  controllable high resolution portrai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  Authors  Publication  \\\n",
       "0   Anime Sketch Coloring with Swish-gated Residua...      NaN          NaN   \n",
       "1     Anita Dataset: An Industrial Animation Dataset       NaN          NaN   \n",
       "2                              Attentioned Deep Paint      NaN          NaN   \n",
       "3                    Automatic Animation Inbetweening      NaN          NaN   \n",
       "4    Automatic Illumination Effects for 2D Characters      NaN          NaN   \n",
       "5      Breaking the cycle—Colleagues are all you need      NaN          NaN   \n",
       "6   Bridging the Gap: Sketch-Aware Interpolation N...      NaN          NaN   \n",
       "7   Building a Manga Dataset ”Manga109” with Annot...      NaN          NaN   \n",
       "8   CAST: CHARACTER LABELING IN ANIMATION USING SE...      NaN          NaN   \n",
       "9   Competition on Multimodal Emotion Recognition ...      NaN          NaN   \n",
       "10  Continual few-shot patch-based learning for an...      NaN          NaN   \n",
       "11  Controlling StyleGANs Using Rough Scribbles vi...      NaN          NaN   \n",
       "12  DAF:RE: A CHALLENGING, CROWD-SOURCED, LARGE-SC...      NaN          NaN   \n",
       "13  DASS-Detector: Domain-Adaptive Self-Supervised...      NaN          NaN   \n",
       "14  Deep Learning-Based Classification of the Pola...      NaN          NaN   \n",
       "15  Disentangled and controllable sketch creation ...      NaN          NaN   \n",
       "16  DreamWaltz: Make a Scene with Complex 3D Anima...      NaN          NaN   \n",
       "17  DyStyle: Dynamic Neural Network for Multi-Attr...      NaN          NaN   \n",
       "18  GANs N’ Roses: Stable, Controllable, Diverse I...      NaN          NaN   \n",
       "19  Generating Full-Body Standing Figures of Anime...      NaN          NaN   \n",
       "20                                              GPT-4      NaN          NaN   \n",
       "21  Integrating Visuospatial, Linguistic and Commo...      NaN          NaN   \n",
       "22  Intelligent Grimm -- Open-ended Visual Storyte...      NaN          NaN   \n",
       "23  InternVL: Scaling up Vision Foundation Models ...      NaN          NaN   \n",
       "24  Learning from the Past: Meta-Continual Learnin...      NaN          NaN   \n",
       "25  Learning Inclusion Matching for Animation Pain...      NaN          NaN   \n",
       "26  Learning Inclusion Matching for Animation Pain...      NaN          NaN   \n",
       "27  Learning to Simplify: Fully Convolutional Netw...      NaN          NaN   \n",
       "28  LVCD: Reference-based Lineart Video Colorizati...      NaN          NaN   \n",
       "29  Manga109Dialog A Large-scale Dialogue Dataset ...      NaN          NaN   \n",
       "30  Mastering Sketching: Adversarial Augmentation ...      NaN          NaN   \n",
       "31  MulT: An End-to-End Multitask Learning Transfo...      NaN          NaN   \n",
       "32  Multi-CartoonGAN for Conditional Artistic Face...      NaN          NaN   \n",
       "33  Occlusion-Aware Manga Character Re-Identificat...      NaN          NaN   \n",
       "34  One missing peace in Vision & Language: A surv...      NaN          NaN   \n",
       "35                Personalized Comic Story Generation      NaN          NaN   \n",
       "36  Raster Manga Vectorization via Primitive-wise ...      NaN          NaN   \n",
       "37  Re:Draw -- Context Aware Translation as a Cont...      NaN          NaN   \n",
       "38  Reference-base Image Composition with Sketch v...      NaN          NaN   \n",
       "39   Sakuga-42M Dataset: Scaling Up Cartoon Research       NaN          NaN   \n",
       "40  SketchColour: Channel Concat Guided DiT-based ...      NaN          NaN   \n",
       "41  Sprite-from-Sprite: Cartoon Animation Decompos...      NaN          NaN   \n",
       "42  StyleGAN-NADA: CLIP-Guided Domain Adaptation o...      NaN          NaN   \n",
       "43  The Visual Language Research Corpus (VLRC) Pro...      NaN          NaN   \n",
       "44     Toon3D: Seeing Cartoons from a New Perspective      NaN          NaN   \n",
       "45  Toonsynth: example-based synthesis of hand-col...      NaN          NaN   \n",
       "46  TransPixar: Advancing Text-to-Video Generation...      NaN          NaN   \n",
       "47  Twin-GAN – Unpaired Cross-Domain Image Transla...      NaN          NaN   \n",
       "48  Two-Step Training: Adjustable Sketch Colouriza...      NaN          NaN   \n",
       "49             Visual adaptation in translated comics      NaN          NaN   \n",
       "50  VToonify: Controllable High-Resolution Portrai...      NaN          NaN   \n",
       "\n",
       "    Year  Type  Key Findings  Relevance     Status  URL  Notes  Tags  \\\n",
       "0    NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "1    NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "2    NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "3    NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "4    NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "5    NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "6    NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "7    NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "8    NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "9    NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "10   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "11   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "12   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "13   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "14   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "15   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "16   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "17   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "18   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "19   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "20   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "21   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "22   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "23   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "24   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "25   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "26   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "27   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "28   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "29   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "30   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "31   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "32   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "33   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "34   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "35   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "36   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "37   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "38   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "39   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "40   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "41   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "42   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "43   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "44   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "45   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "46   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "47   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "48   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "49   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "50   NaN   NaN           NaN        NaN  To Assess  NaN    NaN   NaN   \n",
       "\n",
       "    Citation                                             Source  \\\n",
       "0        NaN                               AwesomeAnimeResearch   \n",
       "1        NaN                         Awesome-Animation-Research   \n",
       "2        NaN                               AwesomeAnimeResearch   \n",
       "3        NaN                               AwesomeAnimeResearch   \n",
       "4        NaN                               AwesomeAnimeResearch   \n",
       "5        NaN                               AwesomeAnimeResearch   \n",
       "6        NaN                         Awesome-Animation-Research   \n",
       "7        NaN                               AwesomeAnimeResearch   \n",
       "8        NaN                               AwesomeAnimeResearch   \n",
       "9        NaN                       awesome-comics-understanding   \n",
       "10       NaN                         Awesome-Animation-Research   \n",
       "11       NaN                               AwesomeAnimeResearch   \n",
       "12       NaN                               AwesomeAnimeResearch   \n",
       "13       NaN                       awesome-comics-understanding   \n",
       "14       NaN                               AwesomeAnimeResearch   \n",
       "15       NaN                               AwesomeAnimeResearch   \n",
       "16       NaN                               AwesomeAnimeResearch   \n",
       "17       NaN                               AwesomeAnimeResearch   \n",
       "18       NaN                               AwesomeAnimeResearch   \n",
       "19       NaN                               AwesomeAnimeResearch   \n",
       "20       NaN                               Awesome-AI4Animation   \n",
       "21       NaN                       awesome-comics-understanding   \n",
       "22       NaN                               Awesome-AI4Animation   \n",
       "23       NaN                               Awesome-AI4Animation   \n",
       "24       NaN                               AwesomeAnimeResearch   \n",
       "25       NaN                               AwesomeAnimeResearch   \n",
       "26       NaN                         Awesome-Animation-Research   \n",
       "27       NaN                               AwesomeAnimeResearch   \n",
       "28       NaN                         Awesome-Animation-Research   \n",
       "29       NaN                       awesome-comics-understanding   \n",
       "30       NaN                               AwesomeAnimeResearch   \n",
       "31       NaN                       awesome-comics-understanding   \n",
       "32       NaN                               AwesomeAnimeResearch   \n",
       "33       NaN                       awesome-comics-understanding   \n",
       "34       NaN                               AwesomeAnimeResearch   \n",
       "35       NaN                       awesome-comics-understanding   \n",
       "36       NaN                               AwesomeAnimeResearch   \n",
       "37       NaN  Awesome-AI4Animation, Awesome-Animation-Resear...   \n",
       "38       NaN                               AwesomeAnimeResearch   \n",
       "39       NaN                         Awesome-Animation-Research   \n",
       "40       NaN                         Awesome-Animation-Research   \n",
       "41       NaN  Awesome-AI4Animation, Awesome-Animation-Resear...   \n",
       "42       NaN                               AwesomeAnimeResearch   \n",
       "43       NaN                       awesome-comics-understanding   \n",
       "44       NaN                         Awesome-Animation-Research   \n",
       "45       NaN   Awesome-AI4Animation, Awesome-Animation-Research   \n",
       "46       NaN                               Awesome-AI4Animation   \n",
       "47       NaN                               AwesomeAnimeResearch   \n",
       "48       NaN                               AwesomeAnimeResearch   \n",
       "49       NaN                       awesome-comics-understanding   \n",
       "50       NaN                               Awesome-AI4Animation   \n",
       "\n",
       "                                              Title_l  \n",
       "0   anime sketch coloring with swish gated residua...  \n",
       "1     anita dataset  an industrial animation dataset   \n",
       "2                              attentioned deep paint  \n",
       "3                    automatic animation inbetweening  \n",
       "4    automatic illumination effects for 2d characters  \n",
       "5      breaking the cycle—colleagues are all you need  \n",
       "6   bridging the gap  sketch aware interpolation n...  \n",
       "7   building a manga dataset ”manga109” with annot...  \n",
       "8   cast  character labeling in animation using se...  \n",
       "9   competition on multimodal emotion recognition ...  \n",
       "10  continual few shot patch based learning for an...  \n",
       "11  controlling stylegans using rough scribbles vi...  \n",
       "12  daf re  a challenging  crowd sourced  large sc...  \n",
       "13  dass detector  domain adaptive self supervised...  \n",
       "14  deep learning based classification of the pola...  \n",
       "15  disentangled and controllable sketch creation ...  \n",
       "16  dreamwaltz  make a scene with complex 3d anima...  \n",
       "17  dystyle  dynamic neural network for multi attr...  \n",
       "18  gans n’ roses  stable  controllable  diverse i...  \n",
       "19  generating full body standing figures of anime...  \n",
       "20                                              gpt 4  \n",
       "21  integrating visuospatial  linguistic and commo...  \n",
       "22  intelligent grimm    open ended visual storyte...  \n",
       "23  internvl  scaling up vision foundation models ...  \n",
       "24  learning from the past  meta continual learnin...  \n",
       "25  learning inclusion matching for animation pain...  \n",
       "26  learning inclusion matching for animation pain...  \n",
       "27  learning to simplify  fully convolutional netw...  \n",
       "28  lvcd  reference based lineart video colorizati...  \n",
       "29  manga109dialog a large scale dialogue dataset ...  \n",
       "30  mastering sketching  adversarial augmentation ...  \n",
       "31  mult  an end to end multitask learning transfo...  \n",
       "32  multi cartoongan for conditional artistic face...  \n",
       "33  occlusion aware manga character re identificat...  \n",
       "34  one missing peace in vision   language  a surv...  \n",
       "35                personalized comic story generation  \n",
       "36  raster manga vectorization via primitive wise ...  \n",
       "37  re draw    context aware translation as a cont...  \n",
       "38  reference base image composition with sketch v...  \n",
       "39   sakuga 42m dataset  scaling up cartoon research   \n",
       "40  sketchcolour  channel concat guided dit based ...  \n",
       "41  sprite from sprite  cartoon animation decompos...  \n",
       "42  stylegan nada  clip guided domain adaptation o...  \n",
       "43  the visual language research corpus  vlrc  pro...  \n",
       "44     toon3d  seeing cartoons from a new perspective  \n",
       "45  toonsynth  example based synthesis of hand col...  \n",
       "46  transpixar  advancing text to video generation...  \n",
       "47  twin gan – unpaired cross domain image transla...  \n",
       "48  two step training  adjustable sketch colouriza...  \n",
       "49             visual adaptation in translated comics  \n",
       "50  vtoonify  controllable high resolution portrai...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['Type'].isna()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6de93161",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans(string.punctuation, \" \"*len(string.punctuation))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0960d93d",
   "metadata": {},
   "source": [
    "# Retrieve Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07eb4a",
   "metadata": {},
   "source": [
    "## CrossRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c36a4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [10:27<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for title in tqdm(df['Title']):\n",
    "    url = f\"https://api.crossref.org/works?query.title={title}&rows=1\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data[\"message\"][\"items\"]:\n",
    "            item = data[\"message\"][\"items\"][0]\n",
    "            results.append({\n",
    "                \"Title\": item.get(\"title\", [\"\"])[0],\n",
    "                \"Authors\": \", \".join(\n",
    "                    f\"{a.get('given', '')} {a.get('family', '')}\"\n",
    "                    for a in item.get(\"author\", [])\n",
    "                ),\n",
    "                \"Year\": item.get(\"issued\", {}).get(\"date-parts\", [[None]])[0][0],\n",
    "                \"Publication\": item.get(\"publisher\", \"\"),\n",
    "                \"URL\": item.get(\"URL\", \"\"),\n",
    "            })\n",
    "        else:\n",
    "            results.append({\n",
    "                \"Title\": title,\n",
    "                \"Authors\": \"\",\n",
    "                \"Year\": \"\",\n",
    "                \"Publication\": \"\",\n",
    "                \"URL\": \"\"\n",
    "            })\n",
    "    else:\n",
    "        results.append({\n",
    "            \"Title\": title,\n",
    "            \"Authors\": \"\",\n",
    "            \"Year\": \"\",\n",
    "            \"Publication\": \"\",\n",
    "            \"URL\": \"\"\n",
    "        })\n",
    "    \n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425bcac1",
   "metadata": {},
   "source": [
    "## Semantic Scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dc31bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 311/311 [04:13<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for title in tqdm(df['Title']):\n",
    "    search_query = \"+\".join([i for i in title.split(\" \")])\n",
    "    url = f\"https://api.semanticscholar.org/graph/v1/paper/search/bulk?query={search_query}&limit=1&fields=title,authors,year,venue,url\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get(\"data\"):\n",
    "            paper = data[\"data\"][0]\n",
    "            results.append({\n",
    "                \"Title\": paper.get(\"title\"),\n",
    "                \"Authors\": \", \".join(a['name'] for a in paper.get(\"authors\", [])),\n",
    "                \"Year\": paper.get(\"year\"),\n",
    "                \"Publication\": paper.get(\"venue\"),\n",
    "                \"URL\": paper.get(\"url\")\n",
    "            })\n",
    "    else:\n",
    "        results.append({\n",
    "            \"Title\": title,\n",
    "            \"Authors\": \"\",\n",
    "            \"Year\": \"\",\n",
    "            \"Publication\": \"\",\n",
    "            \"URL\": \"\"\n",
    "        })\n",
    "    \n",
    "    time.sleep(0.5)  # Avoid rate limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209b7ea0",
   "metadata": {},
   "source": [
    "## Semantic Scholar (no limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "716b0a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [00:46<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for title in tqdm(df['Title']):\n",
    "    search_query = \"+\".join([i for i in title.split(\" \")])\n",
    "    url = f\"https://api.semanticscholar.org/graph/v1/paper/search/bulk?query={search_query}&fields=title,authors,year,venue,url\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data.get(\"data\"):\n",
    "            for paper in data[\"data\"]:\n",
    "                results.append({\n",
    "                    \"Title\": paper.get(\"title\").lower().translate(translator),\n",
    "                    \"Authors\": \", \".join(a['name'] for a in paper.get(\"authors\", [])),\n",
    "                    \"Year\": paper.get(\"year\"),\n",
    "                    \"Publication\": paper.get(\"venue\"),\n",
    "                    \"URL\": paper.get(\"url\")\n",
    "                })\n",
    "    else:\n",
    "        results.append({\n",
    "            \"Title\": title,\n",
    "            \"Authors\": \"\",\n",
    "            \"Year\": \"\",\n",
    "            \"Publication\": \"\",\n",
    "            \"URL\": \"\"\n",
    "        })\n",
    "    \n",
    "    time.sleep(0.5)  # Avoid rate limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995325df",
   "metadata": {},
   "source": [
    "## CrossRef (no limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a23a08e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [01:26<00:00,  1.69s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for title in tqdm(df['Title']):\n",
    "    url = f\"https://api.crossref.org/works?query.title={title}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if data[\"message\"][\"items\"]:\n",
    "            for item in data[\"message\"][\"items\"]:\n",
    "                results.append({\n",
    "                    \"Title\": item.get(\"title\", [\"\"])[0],\n",
    "                    \"Authors\": \", \".join(\n",
    "                        f\"{a.get('given', '')} {a.get('family', '')}\"\n",
    "                        for a in item.get(\"author\", [])\n",
    "                    ),\n",
    "                    \"Year\": item.get(\"issued\", {}).get(\"date-parts\", [[None]])[0][0],\n",
    "                    \"Publication\": item.get(\"publisher\", \"\"),\n",
    "                    \"URL\": item.get(\"URL\", \"\"),\n",
    "                })\n",
    "        else:\n",
    "            results.append({\n",
    "                \"Title\": title,\n",
    "                \"Authors\": \"\",\n",
    "                \"Year\": \"\",\n",
    "                \"Publication\": \"\",\n",
    "                \"URL\": \"\"\n",
    "            })\n",
    "    else:\n",
    "        results.append({\n",
    "            \"Title\": title,\n",
    "            \"Authors\": \"\",\n",
    "            \"Year\": \"\",\n",
    "            \"Publication\": \"\",\n",
    "            \"URL\": \"\"\n",
    "        })\n",
    "    \n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f81724",
   "metadata": {},
   "source": [
    "# Cleaning up the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49c65f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Publication</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anime sketch coloring with swish gated residua...</td>\n",
       "      <td>Gang Liu, Xin Chen, Yanzhong Hu</td>\n",
       "      <td>2019</td>\n",
       "      <td>Springer Singapore</td>\n",
       "      <td>https://doi.org/10.1007/978-981-13-6473-0_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anime sketch colourization using enhanced pix2...</td>\n",
       "      <td>Nikhil Prashant Mudhalwadkar, Hamam Mokayed, L...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Springer Nature Switzerland</td>\n",
       "      <td>https://doi.org/10.1007/978-3-031-47634-1_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anime sketch coloring based on self attention ...</td>\n",
       "      <td>Hang Li, Nianyi Wang, Jie Fang, Ying Jia, Liqi...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Springer Nature Singapore</td>\n",
       "      <td>https://doi.org/10.1007/978-981-99-8552-4_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>style transfer for anime sketches with enhance...</td>\n",
       "      <td>Lvmin Zhang, Yi Ji, Xin Lin, Chunping Liu</td>\n",
       "      <td>2017</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>https://doi.org/10.1109/acpr.2017.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interactive anime sketch colorization with sty...</td>\n",
       "      <td>Ru-Ting Ye, Wei-Li Wang, Ju-Chin Chen, Kawuu W...</td>\n",
       "      <td>2019</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>https://doi.org/10.1109/taai48200.2019.8959911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>controllable neural style transfer for dynamic...</td>\n",
       "      <td>Guilherme Gomes Haetinger, Jingwei Tang, Rapha...</td>\n",
       "      <td>2024</td>\n",
       "      <td>ACM</td>\n",
       "      <td>https://doi.org/10.1145/3641519.3657474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>image purification through controllable neural...</td>\n",
       "      <td>Tongtong Zhao, Yuxiao Yan, Ibrahim Shehi Shehu...</td>\n",
       "      <td>2018</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>https://doi.org/10.1109/ictc.2018.8539637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>computational decomposition of style for contr...</td>\n",
       "      <td>Minchao Li, Shikui Tu, Lei Xu</td>\n",
       "      <td>2019</td>\n",
       "      <td>Springer International Publishing</td>\n",
       "      <td>https://doi.org/10.1007/978-3-030-36204-1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>unsupervised stereoscopic video style transfer</td>\n",
       "      <td>Hassan Imani, Md Baharul Islam, Md Atiqur Rahm...</td>\n",
       "      <td>2023</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>https://doi.org/10.1109/asyu58738.2023.10296716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>style fader generative adversarial networks fo...</td>\n",
       "      <td>Zhiwen Zuo, Lei Zhao, Shuobin Lian, Haibo Chen...</td>\n",
       "      <td>2022</td>\n",
       "      <td>International Joint Conferences on Artificial ...</td>\n",
       "      <td>https://doi.org/10.24963/ijcai.2022/693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>982 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    anime sketch coloring with swish gated residua...   \n",
       "1    anime sketch colourization using enhanced pix2...   \n",
       "2    anime sketch coloring based on self attention ...   \n",
       "3    style transfer for anime sketches with enhance...   \n",
       "4    interactive anime sketch colorization with sty...   \n",
       "..                                                 ...   \n",
       "977  controllable neural style transfer for dynamic...   \n",
       "978  image purification through controllable neural...   \n",
       "979  computational decomposition of style for contr...   \n",
       "980     unsupervised stereoscopic video style transfer   \n",
       "981  style fader generative adversarial networks fo...   \n",
       "\n",
       "                                               Authors  Year  \\\n",
       "0                      Gang Liu, Xin Chen, Yanzhong Hu  2019   \n",
       "1    Nikhil Prashant Mudhalwadkar, Hamam Mokayed, L...  2023   \n",
       "2    Hang Li, Nianyi Wang, Jie Fang, Ying Jia, Liqi...  2023   \n",
       "3            Lvmin Zhang, Yi Ji, Xin Lin, Chunping Liu  2017   \n",
       "4    Ru-Ting Ye, Wei-Li Wang, Ju-Chin Chen, Kawuu W...  2019   \n",
       "..                                                 ...   ...   \n",
       "977  Guilherme Gomes Haetinger, Jingwei Tang, Rapha...  2024   \n",
       "978  Tongtong Zhao, Yuxiao Yan, Ibrahim Shehi Shehu...  2018   \n",
       "979                      Minchao Li, Shikui Tu, Lei Xu  2019   \n",
       "980  Hassan Imani, Md Baharul Islam, Md Atiqur Rahm...  2023   \n",
       "981  Zhiwen Zuo, Lei Zhao, Shuobin Lian, Haibo Chen...  2022   \n",
       "\n",
       "                                           Publication  \\\n",
       "0                                   Springer Singapore   \n",
       "1                          Springer Nature Switzerland   \n",
       "2                            Springer Nature Singapore   \n",
       "3                                                 IEEE   \n",
       "4                                                 IEEE   \n",
       "..                                                 ...   \n",
       "977                                                ACM   \n",
       "978                                               IEEE   \n",
       "979                  Springer International Publishing   \n",
       "980                                               IEEE   \n",
       "981  International Joint Conferences on Artificial ...   \n",
       "\n",
       "                                                 URL  \n",
       "0       https://doi.org/10.1007/978-981-13-6473-0_17  \n",
       "1       https://doi.org/10.1007/978-3-031-47634-1_12  \n",
       "2       https://doi.org/10.1007/978-981-99-8552-4_19  \n",
       "3               https://doi.org/10.1109/acpr.2017.61  \n",
       "4     https://doi.org/10.1109/taai48200.2019.8959911  \n",
       "..                                               ...  \n",
       "977          https://doi.org/10.1145/3641519.3657474  \n",
       "978        https://doi.org/10.1109/ictc.2018.8539637  \n",
       "979      https://doi.org/10.1007/978-3-030-36204-1_2  \n",
       "980  https://doi.org/10.1109/asyu58738.2023.10296716  \n",
       "981          https://doi.org/10.24963/ijcai.2022/693  \n",
       "\n",
       "[982 rows x 5 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results['Title'] = results['Title'].str.translate(translator).str.lower()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3469847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Year</th>\n",
       "      <th>Publication</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anime sketch coloring with swish gated residua...</td>\n",
       "      <td>Gang Liu, Xin Chen, Yanzhong Hu</td>\n",
       "      <td>2019</td>\n",
       "      <td>Springer Singapore</td>\n",
       "      <td>https://doi.org/10.1007/978-981-13-6473-0_17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anime sketch colourization using enhanced pix2...</td>\n",
       "      <td>Nikhil Prashant Mudhalwadkar, Hamam Mokayed, L...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Springer Nature Switzerland</td>\n",
       "      <td>https://doi.org/10.1007/978-3-031-47634-1_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>anime sketch coloring based on self attention ...</td>\n",
       "      <td>Hang Li, Nianyi Wang, Jie Fang, Ying Jia, Liqi...</td>\n",
       "      <td>2023</td>\n",
       "      <td>Springer Nature Singapore</td>\n",
       "      <td>https://doi.org/10.1007/978-981-99-8552-4_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>style transfer for anime sketches with enhance...</td>\n",
       "      <td>Lvmin Zhang, Yi Ji, Xin Lin, Chunping Liu</td>\n",
       "      <td>2017</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>https://doi.org/10.1109/acpr.2017.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>interactive anime sketch colorization with sty...</td>\n",
       "      <td>Ru-Ting Ye, Wei-Li Wang, Ju-Chin Chen, Kawuu W...</td>\n",
       "      <td>2019</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>https://doi.org/10.1109/taai48200.2019.8959911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>controllable neural style transfer for dynamic...</td>\n",
       "      <td>Guilherme Gomes Haetinger, Jingwei Tang, Rapha...</td>\n",
       "      <td>2024</td>\n",
       "      <td>ACM</td>\n",
       "      <td>https://doi.org/10.1145/3641519.3657474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>image purification through controllable neural...</td>\n",
       "      <td>Tongtong Zhao, Yuxiao Yan, Ibrahim Shehi Shehu...</td>\n",
       "      <td>2018</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>https://doi.org/10.1109/ictc.2018.8539637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>computational decomposition of style for contr...</td>\n",
       "      <td>Minchao Li, Shikui Tu, Lei Xu</td>\n",
       "      <td>2019</td>\n",
       "      <td>Springer International Publishing</td>\n",
       "      <td>https://doi.org/10.1007/978-3-030-36204-1_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>unsupervised stereoscopic video style transfer</td>\n",
       "      <td>Hassan Imani, Md Baharul Islam, Md Atiqur Rahm...</td>\n",
       "      <td>2023</td>\n",
       "      <td>IEEE</td>\n",
       "      <td>https://doi.org/10.1109/asyu58738.2023.10296716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>style fader generative adversarial networks fo...</td>\n",
       "      <td>Zhiwen Zuo, Lei Zhao, Shuobin Lian, Haibo Chen...</td>\n",
       "      <td>2022</td>\n",
       "      <td>International Joint Conferences on Artificial ...</td>\n",
       "      <td>https://doi.org/10.24963/ijcai.2022/693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>895 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "0    anime sketch coloring with swish gated residua...   \n",
       "1    anime sketch colourization using enhanced pix2...   \n",
       "2    anime sketch coloring based on self attention ...   \n",
       "3    style transfer for anime sketches with enhance...   \n",
       "4    interactive anime sketch colorization with sty...   \n",
       "..                                                 ...   \n",
       "977  controllable neural style transfer for dynamic...   \n",
       "978  image purification through controllable neural...   \n",
       "979  computational decomposition of style for contr...   \n",
       "980     unsupervised stereoscopic video style transfer   \n",
       "981  style fader generative adversarial networks fo...   \n",
       "\n",
       "                                               Authors  Year  \\\n",
       "0                      Gang Liu, Xin Chen, Yanzhong Hu  2019   \n",
       "1    Nikhil Prashant Mudhalwadkar, Hamam Mokayed, L...  2023   \n",
       "2    Hang Li, Nianyi Wang, Jie Fang, Ying Jia, Liqi...  2023   \n",
       "3            Lvmin Zhang, Yi Ji, Xin Lin, Chunping Liu  2017   \n",
       "4    Ru-Ting Ye, Wei-Li Wang, Ju-Chin Chen, Kawuu W...  2019   \n",
       "..                                                 ...   ...   \n",
       "977  Guilherme Gomes Haetinger, Jingwei Tang, Rapha...  2024   \n",
       "978  Tongtong Zhao, Yuxiao Yan, Ibrahim Shehi Shehu...  2018   \n",
       "979                      Minchao Li, Shikui Tu, Lei Xu  2019   \n",
       "980  Hassan Imani, Md Baharul Islam, Md Atiqur Rahm...  2023   \n",
       "981  Zhiwen Zuo, Lei Zhao, Shuobin Lian, Haibo Chen...  2022   \n",
       "\n",
       "                                           Publication  \\\n",
       "0                                   Springer Singapore   \n",
       "1                          Springer Nature Switzerland   \n",
       "2                            Springer Nature Singapore   \n",
       "3                                                 IEEE   \n",
       "4                                                 IEEE   \n",
       "..                                                 ...   \n",
       "977                                                ACM   \n",
       "978                                               IEEE   \n",
       "979                  Springer International Publishing   \n",
       "980                                               IEEE   \n",
       "981  International Joint Conferences on Artificial ...   \n",
       "\n",
       "                                                 URL  \n",
       "0       https://doi.org/10.1007/978-981-13-6473-0_17  \n",
       "1       https://doi.org/10.1007/978-3-031-47634-1_12  \n",
       "2       https://doi.org/10.1007/978-981-99-8552-4_19  \n",
       "3               https://doi.org/10.1109/acpr.2017.61  \n",
       "4     https://doi.org/10.1109/taai48200.2019.8959911  \n",
       "..                                               ...  \n",
       "977          https://doi.org/10.1145/3641519.3657474  \n",
       "978        https://doi.org/10.1109/ictc.2018.8539637  \n",
       "979      https://doi.org/10.1007/978-3-030-36204-1_2  \n",
       "980  https://doi.org/10.1109/asyu58738.2023.10296716  \n",
       "981          https://doi.org/10.24963/ijcai.2022/693  \n",
       "\n",
       "[895 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = results[results['Authors'] != \"\"].drop_duplicates()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4621e58f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Key Findings</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Status</th>\n",
       "      <th>URL</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Citation</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Title, Authors, Publication, Year, Type, Key Findings, Relevance, Status, URL, Notes, Tags, Citation, Source]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Title_l'] = df['Title'].str.translate(translator).str.lower()\n",
    "merged = df.merge(results, left_on=\"Title_l\", right_on=\"Title\", how=\"left\", suffixes=(\"\", \"_df\"))\n",
    "\n",
    "for col in merged.columns[1:]:\n",
    "    if not col.endswith(\"_df\") and (f'{col}_df' in merged.columns):\n",
    "        merged[col] = merged[f'{col}_df']\n",
    "        merged = merged.drop(columns=[f'{col}_df'])\n",
    "\n",
    "merged = merged.drop(columns=['Title_l', 'Title_df'])\n",
    "merged[merged['Authors'].isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54fbaa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1650/1805314604.py:4: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([prev_df, new_df], ignore_index=True).drop_duplicates(subset=['Title'])\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"./successfully_retrieved.csv\"):\n",
    "    prev_df = pd.read_csv(\"./successfully_retrieved.csv\")\n",
    "    new_df = merged[merged['Authors'].isna() == False]\n",
    "    combined_df = pd.concat([prev_df, new_df], ignore_index=True).drop_duplicates(subset=['Title'])\n",
    "else:\n",
    "    combined_df = merged[merged['Authors'].isna() == False].drop_duplicates()\n",
    "combined_df.to_csv(\"successfully_retrieved.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27e72a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Title'].str.lower().isin(combined_df['Title'].str.lower().tolist()) == False].to_csv(\"Notion.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
