"Title",
"2D shading for cel animation",
"A Comprehensive Study of Deep Video Action Recognition",
"A Drawing Support System for Sketching Aging Anime Faces",
"A Faster R-CNN Based Method for Comic Characters Face Detection",
"A Neural Representation of Sketch Drawings",
"A Note on Data Biases in Generative Models",
"A Novel Double-Tail Generative Adversarial Network for Fast Photo Animation",
"A Simple Framework for Contrastive Learning of Visual Representations",
"A Survey on Machine Reading Comprehension—Tasks, Evaluation Metrics and Benchmark Datasets",
"AccessComics2: Understanding the User Experience of an Accessible Comic Book Reader for Blind People with Textual Sound Effects",
"Adding Conditional Control to Text-to-Image Diffusion Models",
"Analysis Based on Distributed Representations of Various Parts Images in Four-Scene Comics Story Dataset",
"ANIM-400K: A Large-Scale Dataset for Automated End-To-End Dubbing of Video",
"Animate-X: Universal Character Image Animation with Enhanced Motion Representation",
"Animation Anycolor: Enhancing Line Drawing Colorization with Keypoint Matching",
"Animation Line Art Colorization Based on Optical Flow Method",
"Anime Character Colorization using Few-shot Learning",
"Anime like Character Face Generation: A survey",
"Anime Sketch Coloring with Swish-gated Residual U-net and Spectrally Normalized GAN",
"Anime Style Space Exploration Using Metric Learning and Generative Adversarial Networks",
"AnimeCeleb: Large-Scale Animation CelebHeads Dataset for Head Reenactment",
"AnimeDL-2M: Million-Scale AI-Generated Anime Image Detection and Localization in Diffusion Era",
"AnimeGamer: Infinite Anime Life Simulation with Next Game State Prediction",
"AnimeSR: Learning Real-World Super-Resolution Models for Animation Videos",
"Anita Dataset: An Industrial Animation Dataset ",
"Attention-Based Unsupervised Sketch Colorization of Anime Avatar",
"Attentioned Deep Paint",
"Augmenting Conversations With Comic-Style Word Balloons",
"Autoencoding Generative Adversarial Networks",
"Automatic Animation Inbetweening",
"Automatic Illumination Effects for 2D Characters",
"Automatic Sketch Colorization with Tandem Conditional Adversarial Networks",
"Automatic Temporally Coherent Video Colorization",
"Breaking the cycle—Colleagues are all you need",
"Bridging the Gap: Sketch-Aware Interpolation Network for High-Quality Animation Sketch Inbetweening \",
"Building a Manga Dataset ”Manga109” with Annotations for Multimedia Applications",
"CameraCtrl: Enabling Camera Control for Text-to-Video Generation",
"Caricaturation for Human Face Pictures",
"Cartoon Face Recognition: A Benchmark Dataset",
"Cartoon Image Processing: A Survey",
"Cartoonize Images using TinyML Strategies with Transfer Learning",
"CAST: CHARACTER LABELING IN ANIMATION USING SELF-SUPERVISION BY TRACKING",
"CAST: Character Labeling in Animation Using Self‐supervision by Tracking",
"Classification Representations Can be Reused for Downstream Generations",
"Cobra: Efficient Line Art COlorization with BRoAder References",
"CogCartoon: Towards Practical Story Visualization",
"Color Attributes for Object Detection",
"Color Interpolation for Non-Euclidean Color Spaces",
"Colorization for Anime Sketches with Cycle-Consistent Adversarial Network",
"ColorizeDiffusion v2: Enhancing Reference-based Sketch Colorization Through Separating Utilities",
"Comic Image Inpainting via Distance Transform",
"Comic Story Analysis Based on Genre Classification",
"ComicLib: A New Large-Scale Comic Dataset for Sketch Understanding",
"Comicolorization: Semi-Automatic Manga Colorization",
"ComicQA: Contextual Navigation Aid by Hyper-Comic Representation",
"Comics as a Pedagogical Tool for Teaching",
"Competition on Multimodal Emotion Recognition on Comics Scenes",
"Computational Approaches to Comics Analysis",
"Conditional GAN for Small Datasets",
"Continual few-shot patch-based learning for anime-style colorization ",
"Controlling StyleGANs Using Rough Scribbles via One-shot Learning",
"COO/ Comic Onomatopoeia Dataset for Recognizing Arbitrary or Truncated Texts",
"Creative Flow+ Dataset",
"Cross-Domain and Disentangled Face Manipulation with 3D Guidance",
"Cross-Domain Style Mixing for Face Cartoonization",
"CustomCrafter: Customized Video Generation with Preserving Motion and Concept Composition Abilities",
"DAF:RE: A CHALLENGING, CROWD-SOURCED, LARGE-SCALE, LONG-TAILED DATASET FOR ANIME CHARACTER RECOGNITION",
"DASS-Detector: Domain-Adaptive Self-Supervised Pre-Training for Face \& Body Detection in Drawings",
"DATA INSTANCE PRIOR FOR TRANSFER LEARNING IN GANS",
"Decomposing Images into Layers with Advanced Color Blending",
"Deep Learning-Based Classification of the Polar Emotions of “Moe”-Style Cartoon Pictures",
"Dense Multitask Learning to Reconfigure Comics",
"Diffusion in Style",
"Diffutoon: High-Resolution Editable Toon Shading via Diffusion Models",
"DiLight: Digital light table – Inbetweening for 2D animations using guidelines",
"Disentangled and controllable sketch creation based ondisentangling the structure and color enhancement",
"Document Classification and Page Stream Segmentation for Digital Mailroom Applications",
"DoveNet: Deep Image Harmonization via Domain Verification",
"DreamRunner: Fine-Grained Storytelling Video Generation with Retrieval-Augmented Motion Adaptation",
"Dual Color Space Guided Sketch Colorization",
"Dual Loss for Manga Character Recognition with Imbalanced Training Data",
"DyStyle: Dynamic Neural Network for Multi-Attribute-Conditioned Style Editing",
"Efficient Continual Adaptation for Generative Adversarial Networks",
"Encoding in Style: A StyleGAN Encoder for Image-to-Image Translation",
"End-to-End Line Drawing Vectorization",
"Erasing Appearance Preservation in Optimization-based Smoothing",
"Exploring Sketch-based Character Design Guided by Automatic Colorization",
"Feature Quantization Improves GAN Training",
"FEW-SHOT ADAPTATION OF GENERATIVE ADVERSARIAL NETWORKS",
"Fine-Grained Control of Artistic Styles in Image Generation",
"FoleyGen: Visually-Guided Audio Generation",
"Framer: Interactive Frame Interpolation",
"From Speaker to Dubber: Movie Dubbing with Prosody and Duration Consistency Learning",
"Fully Automatic Colorization for Anime Character Considering Accurate Eye Colors",
"GAN Memory with No Forgetting",
"GAN-based Multi-Style Photo Cartoonization",
"GANILLA: Generative adversarial networks for image to illustration translation",
"GANs N’ Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!)",
"GANs N‚Äô Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!)",
"Generating Coherent Comic with Rich Story Using ChatGPT and Stable Diffusion",
"Generating Full-Body Standing Figures of Anime Characters and Its Style Transfer by GAN",
"Generating Manga from Illustrations via Mimicking Manga Creation Workflow",
"Generating Visual Stories with Grounded and Coreferent Characters",
"Generative Probabilistic Image Colorization",
"Good Artists Copy, Great Artists Steal: Model Extraction Attacks Against Image Translation Generative Adversarial Networks",
"GPT-4",
"Guiding Users to Where to Give Color Hints for Efficient Interactive Sketch Colorization via Unsupervised Region Prioritization",
"High-Resolution Image Synthesis with Latent Diffusion Models",
"HistoGAN: Controlling Colors of GAN-Generated and Real Images via Color Histograms",
"Identity-Aware Semi-Supervised Learning for Comic Character Re-Identification",
"Image Colorization: A Survey and Dataset",
"Image-to-Image Translation with Conditional Adversarial Networks",
"Improving Shape Deformation in Unsupervised Image-to-Image Translation",
"Ink-and-Ray: Bas-Relief Meshes for Adding Global Illumination Effects to Hand-Drawn Characters",
"Integrating Visuospatial, Linguistic and Commonsense Structure intoStory Visualization",
"Intelligent Grimm -- Open-ended Visual Storytelling via Latent Diffusion Models",
"Interactive Data Comics",
"InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks",
"Intrinsic Image Harmonization",
"Joint Geometric-Semantic Driven Character Line Drawing Generation",
"Joint Stroke Tracing and Correspondence for 2D Animation",
"KidsGUARD: Fine Grained Approach for Child Unsafe Video Representation and Detection",
"Language-Guided Face Animation by Recurrent StyleGAN-based Generator",
"Large Language Models as Manga Translators: A Case Study",
"LayoutGAN: Generating Graphic Layouts with Wireframe Discriminators",
"Learning Consensus Representation for Weak Style Classification",
"Learning from the Past: Meta-Continual Learning withKnowledge Embedding for Jointly Sketch, Cartoon, andCaricature Face Recognition",
"Learning Inclusion Matching for Animation Paint Bucket Coloriation",
"Learning Inclusion Matching for Animation Paint Bucket Colorization ",
"Learning to Dub Movies via Hierarchical Prosody Models",
"Learning to Simplify: Fully Convolutional Networks for Rough Sketch Cleanup",
"LVCD: Reference-based Lineart Video Colorization with Diffusion Models ",
"Make-A-Storyboard: A General Framework for Storyboard with Disentangled and Merged Control",
"MakeItTalk: Speaker-Aware Talking-Head Animation",
"Manga Colorization",
"Manga109Dialog A Large-scale Dialogue Dataset for Comics Speaker Detection",
"MangaGAN: Unpaired Photo-to-Manga Translation Based on The Methodology of Manga Drawing",
"MangaNinja: Line Art Colorization with Precise Reference Following",
"MangaUB: A Manga Understanding Benchmark for Large Multimodal Models",
"Mastering Sketching: Adversarial Augmentation for Structured Prediction",
"MineGAN++: Mining Generative Models for Efficient Knowledge Transfer to Limited Data Domains",
"Modeling Artistic Workflows for Image Generation and Editing",
"Motion-Conditioned Image Animation for Video Editing",
"MulT: An End-to-End Multitask Learning Transformer",
"Multi-CartoonGAN for Conditional Artistic Face Translation",
"Multi-Teacher Knowledge Distillation For Text Image Machine Translation",
"Neural Optimal Transport",
"Object Detection for Comics using Manga109 Annotations",
"Occlusion-Aware Manga Character Re-Identification with Self-Paced Contrastive Learning",
"One missing peace in Vision & Language: A survey on Comics Understanding",
"Overcoming Long-term Catastrophic Forgetting through Adversarial Neural Pruning and Synaptic Consolidation",
"Parsing-Conditioned Anime Translation: A New Dataset and Method",
"Personalised CLIP or: How to Find Your Vacation Videos",
"Personalized Comic Story Generation",
"PHOG Analysis of Self-Similarity in Aesthetic Images",
"Photorealistic Video Generation with Diffusion Models",
"PhysAnimator: Physics-Guided Generative Cartoon Animation",
"Progressive Deep Feature Learning for Manga Character Recognition via Unlabeled Training Data",
"Pseudo-Supervised Learning for Semantic Multi-Style Transfer",
"Raster Manga Vectorization via Primitive-wise Deep Reinforcement Learning",
"Re:Draw -- Context Aware Translation as a Controllable Method for Artistic Production",
"Reference-base Image Composition with Sketch via Structure-aware Diffusion Model",
"Sakuga-42M Dataset: Scaling Up Cartoon Research ",
"Scaling Concept With Text-Guided Diffusion Models",
"Seamless Manga Inpainting with Semantics Awareness",
"Seg2pix: Few Shot Training Line Art Colorization with Segmented Image Data",
"Semantic Example Guided Image-to-Image Translation",
"Semi-Automatic Colorization Pipeline for Anime Characters and its Evaluation in Production",
"Semi-automatic Manga Colorization Using Conditional Adversarial Networks",
"Skeleton-Driven Inbetweening of Bitmap Character Drawings",
"Sketch-based Anime Hairstyle Editing with Generative Inpainting",
"Sketch-Based Manga Retrieval Using Deep Features",
"Sketch-Guided Scene Image Generation",
"SketchColour: Channel Concat Guided DiT-based Sketch-to-Colour Pipeline for 2D Animation",
"Sprite-from-Sprite: Cartoon Animation Decomposition with Self-supervised Sprite Estimation",
"SSH: A Self-Supervised Framework for Image Harmonization",
"StyleGAN-NADA: CLIP-Guided Domain Adaptation of Image Generators",
"Stylized-Colorization for Line Arts",
"Synthesis of Screentone Patterns of Manga Characters",
"Taming Visually Guided Sound Generation",
"The Visual Language Research Corpus (VLRC) Project",
"Thin-Plate Spline-based Interpolation for Animation Line Inbetweening",
"Toon3D: Seeing Cartoons from a New Perspective",
"Toonsynth: example-based synthesis of hand-colored cartoon animations",
"Towards Diverse Anime Face Generation: Active Label Completion and Style Feature Network",
"Towards Layer-wise Image Vectorization",
"Towards Solving Multimodal Comprehension",
"Transfer Learning for Pose Estimation of Illustrated Characters",
"TransPixar: Advancing Text-to-Video Generation with Transparency",
"Turn Real People into Anime Cartoonization",
"Twin-GAN – Unpaired Cross-Domain Image Translation with Weight-Sharing GANs",
"Twin-GAN ‚Äì Unpaired Cross-Domain Image Translation with Weight-Sharing GANs",
"Two-stage Sketch Colorization",
"Two-Stage Sketch Colorization With Color Parsing",
"Two-Step Training: Adjustable Sketch Colourization via Reference Image and Text Tag",
"U-GAT-IT: Unsupervised Generative Attentional Networks with Adaptive Layer-Instance Normalization for Image-to-Image Translation",
"Unaligned Image-to-Image Translation by Learning to Reweight",
"Unconstrained Text Detection in Manga: a New Dataset and Baseline",
"Universal Face Restoration With Memorized Modulation",
"Unpaired Image-to-Image Translation using Adversarial Consistency Loss",
"Unpaired Image-to-Image Translation using Negative Learning for Noisy Patches",
"Unsupervised Discovery of Disentangled Manifolds in GANs",
"Unsupervised Discovery of Interpretable Directions in the GAN Latent Space",
"Unsupervised Image-to-Image Translation via Pre-trained StyleGAN2 Network",
"Unsupervised Learning of Compositional Energy Concepts",
"User Guided Digital Artwork Colorization",
"User-Guided Deep Anime Line Art Colorization with Conditional Adversarial Networks",
"User-Guided Line Art Flat Filling with Split Filling Mechanism",
"V2C: Visual Voice Cloning",
"VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided Planning",
"VidMuse: A Simple Video-to-Music Generation Framework with Long-Short-Term Modeling",
"Visual adaptation in translated comics",
"VToonify: Controllable High-Resolution Portrait Video Style Transfer",
"Zero-Shot Object Detection with Textual Descriptions",